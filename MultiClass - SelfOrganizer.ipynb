{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Iris Dataset - SOFENN Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate multi-class classification with SOFENN on classic Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, load_model, clone_model\n",
    "\n",
    "from sofenn import SelfOrganizer\n",
    "from sofenn.FuzzyNetwork import FuzzyNetwork\n",
    "from sofenn.layers import FuzzyLayer, NormalizedLayer, WeightedLayer, OutputLayer\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and prep Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in iris dataset\n",
    "iris = datasets.load_iris()\n",
    "# create one-hot encoded vector for each class\n",
    "Y = []\n",
    "for y in iris.target:\n",
    "    tmp = np.zeros(3)\n",
    "    tmp[y] = 1\n",
    "    Y.append(tmp)\n",
    "Y = np.array(Y)\n",
    "    \n",
    "# split to train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Self Organizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SelfOrganizer(\n",
    "             ksig=1.12, max_widens=250,          # adding neuron or widening centers\n",
    "             prune_tol=0.85, k_rmse=0.1,          # pruning parameters\n",
    "             debug=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Fuzzy Network with 25 neurons...\n",
      "WARNING:tensorflow:From /miniconda3/envs/sofenn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "...Model successfully built!\n"
     ]
    }
   ],
   "source": [
    "start_neurons = 25\n",
    "\n",
    "sofnn.build_network(\n",
    "                 X_train, X_test, y_train, y_test,        # data attributes\n",
    "                 neurons=start_neurons, max_neurons=100,  # neuron initialization parameters\n",
    "                 ifpart_thresh=0.1354,                    # ifpart and error thresholds\n",
    "                 prob_type='classification'               # type of problem (classification/regression)\n",
    ")\n",
    "\n",
    "network = sofnn.network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Inputs (InputLayer)             (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FuzzyRules (FuzzyLayer)         (None, 25)           200         Inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Normalization (NormalizedLayer) (None, 25)           0           FuzzyRules[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weights (WeightedLayer)         (None, 25)           125         Inputs[0][0]                     \n",
      "                                                                 Normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RawOutput (OutputLayer)         (None, 1)            0           Weights[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Dense)                 (None, 3)            6           RawOutput[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 331\n",
      "Trainable params: 331\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "loss = sofnn.network.loss_function\n",
    "optimizer = 'adam'\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "sofnn.compile_model(init_c=True, random=True, init_s=True, s_0=4.0,\n",
    "                    loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "WARNING:tensorflow:From /miniconda3/envs/sofenn/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/45\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 10.2228 - binary_accuracy: 0.6667\n",
      "Epoch 2/45\n",
      "135/135 [==============================] - 0s 256us/step - loss: 10.1619 - binary_accuracy: 0.6667\n",
      "Epoch 3/45\n",
      "135/135 [==============================] - 0s 272us/step - loss: 10.1068 - binary_accuracy: 0.6667\n",
      "Epoch 4/45\n",
      "135/135 [==============================] - 0s 257us/step - loss: 10.0402 - binary_accuracy: 0.6667\n",
      "Epoch 5/45\n",
      "135/135 [==============================] - 0s 119us/step - loss: 9.9957 - binary_accuracy: 0.6667\n",
      "Epoch 6/45\n",
      "135/135 [==============================] - 0s 141us/step - loss: 9.9073 - binary_accuracy: 0.6667\n",
      "Epoch 7/45\n",
      "135/135 [==============================] - 0s 189us/step - loss: 9.8523 - binary_accuracy: 0.6667\n",
      "Epoch 8/45\n",
      "135/135 [==============================] - 0s 146us/step - loss: 9.8485 - binary_accuracy: 0.6667\n",
      "Epoch 9/45\n",
      "135/135 [==============================] - 0s 136us/step - loss: 9.7716 - binary_accuracy: 0.6667\n",
      "Epoch 10/45\n",
      "135/135 [==============================] - 0s 173us/step - loss: 9.6395 - binary_accuracy: 0.6667\n",
      "Epoch 11/45\n",
      "135/135 [==============================] - 0s 162us/step - loss: 9.6873 - binary_accuracy: 0.6667\n",
      "Epoch 12/45\n",
      "135/135 [==============================] - 0s 131us/step - loss: 9.5630 - binary_accuracy: 0.6667\n",
      "Epoch 13/45\n",
      "135/135 [==============================] - 0s 181us/step - loss: 9.4791 - binary_accuracy: 0.6667\n",
      "Epoch 14/45\n",
      "135/135 [==============================] - 0s 198us/step - loss: 9.3864 - binary_accuracy: 0.6691\n",
      "Epoch 15/45\n",
      "135/135 [==============================] - 0s 151us/step - loss: 9.3848 - binary_accuracy: 0.6765\n",
      "Epoch 16/45\n",
      "135/135 [==============================] - 0s 169us/step - loss: 9.2993 - binary_accuracy: 0.6815\n",
      "Epoch 17/45\n",
      "135/135 [==============================] - 0s 166us/step - loss: 9.1792 - binary_accuracy: 0.6864\n",
      "Epoch 18/45\n",
      "135/135 [==============================] - 0s 176us/step - loss: 9.0879 - binary_accuracy: 0.6889\n",
      "Epoch 19/45\n",
      "135/135 [==============================] - 0s 157us/step - loss: 9.0894 - binary_accuracy: 0.6988\n",
      "Epoch 20/45\n",
      "135/135 [==============================] - 0s 164us/step - loss: 8.9862 - binary_accuracy: 0.7037\n",
      "Epoch 21/45\n",
      "135/135 [==============================] - 0s 173us/step - loss: 8.8925 - binary_accuracy: 0.7062\n",
      "Epoch 22/45\n",
      "135/135 [==============================] - 0s 154us/step - loss: 8.8930 - binary_accuracy: 0.7160\n",
      "Epoch 23/45\n",
      "135/135 [==============================] - 0s 156us/step - loss: 8.7913 - binary_accuracy: 0.7210\n",
      "Epoch 24/45\n",
      "135/135 [==============================] - 0s 157us/step - loss: 8.7457 - binary_accuracy: 0.7235\n",
      "Epoch 25/45\n",
      "135/135 [==============================] - 0s 160us/step - loss: 8.7175 - binary_accuracy: 0.7284\n",
      "Epoch 26/45\n",
      "135/135 [==============================] - 0s 171us/step - loss: 8.6095 - binary_accuracy: 0.7358\n",
      "Epoch 27/45\n",
      "135/135 [==============================] - 0s 157us/step - loss: 8.5453 - binary_accuracy: 0.7383\n",
      "Epoch 28/45\n",
      "135/135 [==============================] - 0s 155us/step - loss: 8.4234 - binary_accuracy: 0.7432\n",
      "Epoch 29/45\n",
      "135/135 [==============================] - 0s 160us/step - loss: 8.3804 - binary_accuracy: 0.7432\n",
      "Epoch 30/45\n",
      "135/135 [==============================] - 0s 193us/step - loss: 8.2222 - binary_accuracy: 0.7432\n",
      "Epoch 31/45\n",
      "135/135 [==============================] - 0s 139us/step - loss: 8.2280 - binary_accuracy: 0.7457\n",
      "Epoch 32/45\n",
      "135/135 [==============================] - 0s 161us/step - loss: 8.1324 - binary_accuracy: 0.7457\n",
      "Epoch 33/45\n",
      "135/135 [==============================] - 0s 137us/step - loss: 8.1024 - binary_accuracy: 0.7481\n",
      "Epoch 34/45\n",
      "135/135 [==============================] - 0s 162us/step - loss: 8.0912 - binary_accuracy: 0.7481\n",
      "Epoch 35/45\n",
      "135/135 [==============================] - 0s 181us/step - loss: 7.8643 - binary_accuracy: 0.7481\n",
      "Epoch 36/45\n",
      "135/135 [==============================] - 0s 141us/step - loss: 7.8254 - binary_accuracy: 0.7531\n",
      "Epoch 37/45\n",
      "135/135 [==============================] - 0s 159us/step - loss: 7.7575 - binary_accuracy: 0.7531\n",
      "Epoch 38/45\n",
      "135/135 [==============================] - 0s 146us/step - loss: 7.7169 - binary_accuracy: 0.7531\n",
      "Epoch 39/45\n",
      "135/135 [==============================] - 0s 163us/step - loss: 7.5982 - binary_accuracy: 0.7531\n",
      "Epoch 40/45\n",
      "135/135 [==============================] - 0s 153us/step - loss: 7.5223 - binary_accuracy: 0.7580\n",
      "Epoch 41/45\n",
      "135/135 [==============================] - 0s 164us/step - loss: 7.4542 - binary_accuracy: 0.7679\n",
      "Epoch 42/45\n",
      "135/135 [==============================] - 0s 145us/step - loss: 7.3677 - binary_accuracy: 0.7901\n",
      "Epoch 43/45\n",
      "135/135 [==============================] - 0s 173us/step - loss: 7.1978 - binary_accuracy: 0.8272\n",
      "Epoch 44/45\n",
      "135/135 [==============================] - 0s 213us/step - loss: 7.3316 - binary_accuracy: 0.8494\n",
      "Epoch 45/45\n",
      "135/135 [==============================] - 0s 154us/step - loss: 7.0394 - binary_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "sofnn.train_model(epochs=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.3678393 ,  5.331752  ,  6.570406  ,  5.581352  ,  4.881678  ,\n",
       "          5.9167843 ,  7.1881914 ,  5.3665032 ,  7.6236305 ,  8.0159855 ,\n",
       "          5.8624344 ,  4.608199  ,  6.477     ,  4.8983693 ,  6.5887704 ,\n",
       "          5.1603847 ,  6.853785  ,  6.0154552 ,  6.557422  ,  7.483419  ,\n",
       "          4.992675  ,  5.7149725 ,  4.7968445 ,  5.4604735 ,  4.863268  ],\n",
       "        [ 2.8398733 ,  2.4169877 ,  2.6676095 ,  2.5322669 ,  3.447356  ,\n",
       "          2.8026128 ,  3.0178037 ,  2.4554107 ,  2.8662074 ,  3.6491075 ,\n",
       "          2.620231  ,  3.1173267 ,  3.3742304 ,  3.6590462 ,  2.572337  ,\n",
       "          3.3613102 ,  2.7449706 ,  2.6062071 ,  2.477744  ,  2.9662352 ,\n",
       "          3.9319863 ,  2.5605433 ,  3.280608  ,  4.260354  ,  2.676512  ],\n",
       "        [ 5.1843686 ,  3.938379  ,  5.901959  ,  3.8689718 ,  1.1793845 ,\n",
       "          4.7958627 ,  5.2032733 ,  3.964856  ,  6.381959  ,  6.6843867 ,\n",
       "          4.305315  ,  1.3811549 ,  5.692817  ,  1.6770291 ,  5.200583  ,\n",
       "          1.2796346 ,  4.8575006 ,  4.6582804 ,  5.2784095 ,  6.5643735 ,\n",
       "          1.2981778 ,  5.142561  ,  1.1850038 ,  1.2973114 ,  2.7205813 ],\n",
       "        [ 2.0876052 ,  1.0156515 ,  2.0880718 ,  0.7641217 , -0.03297931,\n",
       "          1.812836  ,  1.8021287 ,  1.051931  ,  2.1843867 ,  2.2987523 ,\n",
       "          1.5070806 , -0.02490385,  2.5902884 ,  0.16962968,  2.1016953 ,\n",
       "          0.15604347,  1.5509032 ,  1.6495076 ,  2.1824682 ,  2.1044934 ,\n",
       "         -0.09821244,  2.5333962 , -0.02563862,  0.17538257,  0.8118578 ]],\n",
       "       dtype=float32),\n",
       " array([[3.8048217, 3.7279344, 3.7063468, 3.7835546, 3.7552624, 3.813959 ,\n",
       "         3.6976762, 3.7617126, 3.7316782, 3.7625132, 4.021197 , 3.773738 ,\n",
       "         3.7780328, 3.7727182, 3.7570786, 3.7609994, 3.7243347, 3.7659745,\n",
       "         3.7962508, 3.7649617, 3.7772007, 3.856098 , 3.7668142, 3.7811995,\n",
       "         3.7453926],\n",
       "        [3.7495713, 3.7267556, 3.7272413, 3.9030776, 4.125936 , 3.8092024,\n",
       "         3.8055384, 3.7806396, 3.9381163, 4.098973 , 3.7529964, 4.1568546,\n",
       "         3.8811145, 4.1580186, 3.7855744, 4.15583  , 3.7611568, 3.709379 ,\n",
       "         3.8822942, 3.9758384, 4.1552644, 3.7631264, 4.134341 , 4.1277347,\n",
       "         4.212417 ],\n",
       "        [3.7022645, 3.709493 , 3.6825957, 3.7682846, 3.737972 , 3.8188887,\n",
       "         3.6948185, 3.7368526, 3.7022533, 3.6862502, 3.8299432, 3.754633 ,\n",
       "         3.697741 , 3.753561 , 3.718546 , 3.7433763, 3.720454 , 3.7116342,\n",
       "         3.698272 , 3.7097313, 3.75753  , 3.811976 , 3.7528129, 3.7634501,\n",
       "         3.72646  ],\n",
       "        [3.692462 , 3.6859365, 3.6742003, 3.744243 , 3.7219405, 3.860863 ,\n",
       "         3.7293456, 3.7148557, 3.6891367, 3.6759624, 3.8709695, 3.7434742,\n",
       "         3.6941814, 3.7388394, 3.702848 , 3.7232442, 3.8807185, 3.7102015,\n",
       "         3.6910424, 3.7121308, 3.7454581, 3.8693373, 3.7395158, 3.7460077,\n",
       "         3.7187715]], dtype=float32),\n",
       " array([[-0.02501293, -0.08501959,  0.05115468, -0.16913258, -0.17744873,\n",
       "         -0.00687988, -0.02213819, -0.13881095,  0.07851772,  0.12200587,\n",
       "         -0.06081994, -0.24720083,  0.06568789, -0.17160398,  0.00489723,\n",
       "         -0.16814154,  0.02401317, -0.03396388,  0.00437387,  0.13449372,\n",
       "         -0.20289955,  0.0277427 , -0.23140505, -0.1966662 , -0.16250229],\n",
       "        [ 0.09452014, -0.03318857,  0.15246549, -0.06942599, -0.2174656 ,\n",
       "         -0.00591872,  0.06719889, -0.05251333,  0.13339868,  0.14866471,\n",
       "          0.03493994, -0.17073187,  0.12030155, -0.22529325,  0.05981455,\n",
       "         -0.20987579,  0.10089777, -0.00199551,  0.09238373,  0.11456628,\n",
       "         -0.23361564,  0.02411968, -0.1741463 , -0.2112149 , -0.18121213],\n",
       "        [ 0.03328598, -0.159708  ,  0.02584427, -0.16895837, -0.15981087,\n",
       "         -0.0891566 ,  0.03268   , -0.14072162,  0.15340337,  0.09025925,\n",
       "         -0.14179507, -0.1725192 ,  0.09087282, -0.19135751, -0.0084213 ,\n",
       "         -0.19148582, -0.02536701, -0.03650414,  0.03570246,  0.05909145,\n",
       "         -0.24713466, -0.03216583, -0.1791129 , -0.1818292 , -0.22519268],\n",
       "        [ 0.13243973,  0.09990127,  0.10715691,  0.08895828, -0.08385354,\n",
       "          0.12379419,  0.18507668,  0.11025435,  0.18463627,  0.19136989,\n",
       "          0.16397735, -0.05496101,  0.14261523,  0.014589  ,  0.1852545 ,\n",
       "         -0.08430371,  0.14541085,  0.10555821,  0.18434115,  0.2116718 ,\n",
       "         -0.09059661,  0.10223033, -0.0808556 ,  0.00355088,  0.09454863],\n",
       "        [ 0.18321976,  0.16644561,  0.12642483,  0.12217869,  0.05219448,\n",
       "          0.1839186 ,  0.15762086,  0.13338959,  0.17783009,  0.17362207,\n",
       "          0.1390462 ,  0.0336629 ,  0.16749066,  0.12573047,  0.15767308,\n",
       "          0.10160787,  0.1467009 ,  0.13746856,  0.19238092,  0.21027853,\n",
       "          0.11433733,  0.14214677,  0.06015009,  0.09306832,  0.15652573]],\n",
       "       dtype=float32),\n",
       " array([[-0.67898667, -0.33913767,  0.9537499 ]], dtype=float32),\n",
       " array([ 0.10426174, -0.02130238, -0.0909103 ], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofnn.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding neuron...\n",
      "Neuron successfully added! - 26 current neurons...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofnn.add_neuron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.3678393 ,  5.331752  ,  6.570406  ,  5.581352  ,  4.881678  ,\n",
       "          5.9167843 ,  7.1881914 ,  5.3665032 ,  7.6236305 ,  8.0159855 ,\n",
       "          5.8624344 ,  4.608199  ,  6.477     ,  4.8983693 ,  6.5887704 ,\n",
       "          5.1603847 ,  6.853785  ,  6.0154552 ,  6.557422  ,  7.483419  ,\n",
       "          4.992675  ,  5.7149725 ,  4.7968445 ,  5.4604735 ,  4.863268  ,\n",
       "          6.3678393 ],\n",
       "        [ 2.8398733 ,  2.4169877 ,  2.6676095 ,  2.5322669 ,  3.447356  ,\n",
       "          2.8026128 ,  3.0178037 ,  2.4554107 ,  2.8662074 ,  3.6491075 ,\n",
       "          2.620231  ,  3.1173267 ,  3.3742304 ,  3.6590462 ,  2.572337  ,\n",
       "          3.3613102 ,  2.7449706 ,  2.6062071 ,  2.477744  ,  2.9662352 ,\n",
       "          3.9319863 ,  2.5605433 ,  3.280608  ,  4.260354  ,  2.676512  ,\n",
       "          2.8398733 ],\n",
       "        [ 5.1843686 ,  3.938379  ,  5.901959  ,  3.8689718 ,  1.1793845 ,\n",
       "          4.7958627 ,  5.2032733 ,  3.964856  ,  6.381959  ,  6.6843867 ,\n",
       "          4.305315  ,  1.3811549 ,  5.692817  ,  1.6770291 ,  5.200583  ,\n",
       "          1.2796346 ,  4.8575006 ,  4.6582804 ,  5.2784095 ,  6.5643735 ,\n",
       "          1.2981778 ,  5.142561  ,  1.1850038 ,  1.2973114 ,  2.7205813 ,\n",
       "          1.2981778 ],\n",
       "        [ 2.0876052 ,  1.0156515 ,  2.0880718 ,  0.7641217 , -0.03297931,\n",
       "          1.812836  ,  1.8021287 ,  1.051931  ,  2.1843867 ,  2.2987523 ,\n",
       "          1.5070806 , -0.02490385,  2.5902884 ,  0.16962968,  2.1016953 ,\n",
       "          0.15604347,  1.5509032 ,  1.6495076 ,  2.1824682 ,  2.1044934 ,\n",
       "         -0.09821244,  2.5333962 , -0.02563862,  0.17538257,  0.8118578 ,\n",
       "          1.1925926 ]], dtype=float32),\n",
       " array([[3.8048217, 3.7279344, 3.7063468, 3.7835546, 3.7552624, 3.813959 ,\n",
       "         3.6976762, 3.7617126, 3.7316782, 3.7625132, 4.021197 , 3.773738 ,\n",
       "         3.7780328, 3.7727182, 3.7570786, 3.7609994, 3.7243347, 3.7659745,\n",
       "         3.7962508, 3.7649617, 3.7772007, 3.856098 , 3.7668142, 3.7811995,\n",
       "         3.7453926, 3.8048217],\n",
       "        [3.7495713, 3.7267556, 3.7272413, 3.9030776, 4.125936 , 3.8092024,\n",
       "         3.8055384, 3.7806396, 3.9381163, 4.098973 , 3.7529964, 4.1568546,\n",
       "         3.8811145, 4.1580186, 3.7855744, 4.15583  , 3.7611568, 3.709379 ,\n",
       "         3.8822942, 3.9758384, 4.1552644, 3.7631264, 4.134341 , 4.1277347,\n",
       "         4.212417 , 3.7495713],\n",
       "        [3.7022645, 3.709493 , 3.6825957, 3.7682846, 3.737972 , 3.8188887,\n",
       "         3.6948185, 3.7368526, 3.7022533, 3.6862502, 3.8299432, 3.754633 ,\n",
       "         3.697741 , 3.753561 , 3.718546 , 3.7433763, 3.720454 , 3.7116342,\n",
       "         3.698272 , 3.7097313, 3.75753  , 3.811976 , 3.7528129, 3.7634501,\n",
       "         3.72646  , 3.75753  ],\n",
       "        [3.692462 , 3.6859365, 3.6742003, 3.744243 , 3.7219405, 3.860863 ,\n",
       "         3.7293456, 3.7148557, 3.6891367, 3.6759624, 3.8709695, 3.7434742,\n",
       "         3.6941814, 3.7388394, 3.702848 , 3.7232442, 3.8807185, 3.7102015,\n",
       "         3.6910424, 3.7121308, 3.7454581, 3.8693373, 3.7395158, 3.7460077,\n",
       "         3.7187715, 2.5555701]], dtype=float32),\n",
       " array([[-0.02501293, -0.08501959,  0.05115468, -0.16913258, -0.17744873,\n",
       "         -0.00687988, -0.02213819, -0.13881095,  0.07851772,  0.12200587,\n",
       "         -0.06081994, -0.24720083,  0.06568789, -0.17160398,  0.00489723,\n",
       "         -0.16814154,  0.02401317, -0.03396388,  0.00437387,  0.13449372,\n",
       "         -0.20289955,  0.0277427 , -0.23140505, -0.1966662 , -0.16250229,\n",
       "          1.        ],\n",
       "        [ 0.09452014, -0.03318857,  0.15246549, -0.06942599, -0.2174656 ,\n",
       "         -0.00591872,  0.06719889, -0.05251333,  0.13339868,  0.14866471,\n",
       "          0.03493994, -0.17073187,  0.12030155, -0.22529325,  0.05981455,\n",
       "         -0.20987579,  0.10089777, -0.00199551,  0.09238373,  0.11456628,\n",
       "         -0.23361564,  0.02411968, -0.1741463 , -0.2112149 , -0.18121213,\n",
       "          1.        ],\n",
       "        [ 0.03328598, -0.159708  ,  0.02584427, -0.16895837, -0.15981087,\n",
       "         -0.0891566 ,  0.03268   , -0.14072162,  0.15340337,  0.09025925,\n",
       "         -0.14179507, -0.1725192 ,  0.09087282, -0.19135751, -0.0084213 ,\n",
       "         -0.19148582, -0.02536701, -0.03650414,  0.03570246,  0.05909145,\n",
       "         -0.24713466, -0.03216583, -0.1791129 , -0.1818292 , -0.22519268,\n",
       "          1.        ],\n",
       "        [ 0.13243973,  0.09990127,  0.10715691,  0.08895828, -0.08385354,\n",
       "          0.12379419,  0.18507668,  0.11025435,  0.18463627,  0.19136989,\n",
       "          0.16397735, -0.05496101,  0.14261523,  0.014589  ,  0.1852545 ,\n",
       "         -0.08430371,  0.14541085,  0.10555821,  0.18434115,  0.2116718 ,\n",
       "         -0.09059661,  0.10223033, -0.0808556 ,  0.00355088,  0.09454863,\n",
       "          1.        ],\n",
       "        [ 0.18321976,  0.16644561,  0.12642483,  0.12217869,  0.05219448,\n",
       "          0.1839186 ,  0.15762086,  0.13338959,  0.17783009,  0.17362207,\n",
       "          0.1390462 ,  0.0336629 ,  0.16749066,  0.12573047,  0.15767308,\n",
       "          0.10160787,  0.1467009 ,  0.13746856,  0.19238092,  0.21027853,\n",
       "          0.11433733,  0.14214677,  0.06015009,  0.09306832,  0.15652573,\n",
       "          1.        ]], dtype=float32),\n",
       " array([[-0.67898667, -0.33913767,  0.9537499 ]], dtype=float32),\n",
       " array([ 0.10426174, -0.02130238, -0.0909103 ], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofnn.model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning Nuerons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sofnn.prune_neurons()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kwargs = ['epochs']\n",
    "\n",
    "def test(**kwargs):\n",
    "    if 'epochs' in kwargs:\n",
    "        print(kwargs)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding neuron...\n",
      "Neuron successfully added! - 27 current neurons...\n",
      "Training model...\n",
      "Epoch 1/250\n",
      "135/135 [==============================] - 1s 6ms/step - loss: 10.3546 - binary_accuracy: 0.6617\n",
      "Epoch 2/250\n",
      "135/135 [==============================] - 0s 163us/step - loss: 9.7206 - binary_accuracy: 0.6617\n",
      "Epoch 3/250\n",
      "135/135 [==============================] - 0s 214us/step - loss: 8.9357 - binary_accuracy: 0.6741\n",
      "Epoch 4/250\n",
      "135/135 [==============================] - 0s 214us/step - loss: 8.3987 - binary_accuracy: 0.7358\n",
      "Epoch 5/250\n",
      "135/135 [==============================] - 0s 254us/step - loss: 8.2367 - binary_accuracy: 0.7531\n",
      "Epoch 6/250\n",
      "135/135 [==============================] - 0s 214us/step - loss: 8.0415 - binary_accuracy: 0.7383\n",
      "Epoch 7/250\n",
      "135/135 [==============================] - 0s 128us/step - loss: 7.9462 - binary_accuracy: 0.7383\n",
      "Epoch 8/250\n",
      "135/135 [==============================] - 0s 113us/step - loss: 7.6771 - binary_accuracy: 0.7481\n",
      "Epoch 9/250\n",
      "135/135 [==============================] - 0s 176us/step - loss: 7.5599 - binary_accuracy: 0.7704\n",
      "Epoch 10/250\n",
      "135/135 [==============================] - 0s 139us/step - loss: 7.3575 - binary_accuracy: 0.8173\n",
      "Epoch 11/250\n",
      "135/135 [==============================] - 0s 122us/step - loss: 7.1535 - binary_accuracy: 0.8568\n",
      "Epoch 12/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 7.0256 - binary_accuracy: 0.8667\n",
      "Epoch 13/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 6.9148 - binary_accuracy: 0.8691\n",
      "Epoch 14/250\n",
      "135/135 [==============================] - 0s 136us/step - loss: 6.7358 - binary_accuracy: 0.8716\n",
      "Epoch 15/250\n",
      "135/135 [==============================] - 0s 167us/step - loss: 6.6094 - binary_accuracy: 0.8716\n",
      "Epoch 16/250\n",
      "135/135 [==============================] - 0s 148us/step - loss: 6.5076 - binary_accuracy: 0.8716\n",
      "Epoch 17/250\n",
      "135/135 [==============================] - 0s 186us/step - loss: 6.3786 - binary_accuracy: 0.8716\n",
      "Epoch 18/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 6.2564 - binary_accuracy: 0.8716\n",
      "Epoch 19/250\n",
      "135/135 [==============================] - 0s 167us/step - loss: 6.1598 - binary_accuracy: 0.8716\n",
      "Epoch 20/250\n",
      "135/135 [==============================] - 0s 145us/step - loss: 6.1253 - binary_accuracy: 0.8716\n",
      "Epoch 21/250\n",
      "135/135 [==============================] - 0s 143us/step - loss: 5.8946 - binary_accuracy: 0.8716\n",
      "Epoch 22/250\n",
      "135/135 [==============================] - 0s 184us/step - loss: 5.7568 - binary_accuracy: 0.8716\n",
      "Epoch 23/250\n",
      "135/135 [==============================] - 0s 173us/step - loss: 5.8051 - binary_accuracy: 0.8716\n",
      "Epoch 24/250\n",
      "135/135 [==============================] - 0s 133us/step - loss: 5.6896 - binary_accuracy: 0.8716\n",
      "Epoch 25/250\n",
      "135/135 [==============================] - 0s 171us/step - loss: 5.5024 - binary_accuracy: 0.8716\n",
      "Epoch 26/250\n",
      "135/135 [==============================] - 0s 141us/step - loss: 5.5102 - binary_accuracy: 0.8716\n",
      "Epoch 27/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 5.4230 - binary_accuracy: 0.8716\n",
      "Epoch 28/250\n",
      "135/135 [==============================] - 0s 152us/step - loss: 5.2438 - binary_accuracy: 0.8716\n",
      "Epoch 29/250\n",
      "135/135 [==============================] - 0s 150us/step - loss: 5.2861 - binary_accuracy: 0.8716\n",
      "Epoch 30/250\n",
      "135/135 [==============================] - 0s 139us/step - loss: 5.2983 - binary_accuracy: 0.8716\n",
      "Epoch 31/250\n",
      "135/135 [==============================] - 0s 177us/step - loss: 5.2074 - binary_accuracy: 0.8716\n",
      "Epoch 32/250\n",
      "135/135 [==============================] - 0s 151us/step - loss: 5.1281 - binary_accuracy: 0.8716\n",
      "Epoch 33/250\n",
      "135/135 [==============================] - 0s 178us/step - loss: 4.8968 - binary_accuracy: 0.8691\n",
      "Epoch 34/250\n",
      "135/135 [==============================] - 0s 145us/step - loss: 5.0510 - binary_accuracy: 0.8691\n",
      "Epoch 35/250\n",
      "135/135 [==============================] - 0s 131us/step - loss: 4.9200 - binary_accuracy: 0.8691\n",
      "Epoch 36/250\n",
      "135/135 [==============================] - 0s 171us/step - loss: 4.7966 - binary_accuracy: 0.8691\n",
      "Epoch 37/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 4.8765 - binary_accuracy: 0.8691\n",
      "Epoch 38/250\n",
      "135/135 [==============================] - 0s 132us/step - loss: 4.6627 - binary_accuracy: 0.8691\n",
      "Epoch 39/250\n",
      "135/135 [==============================] - 0s 172us/step - loss: 4.6900 - binary_accuracy: 0.8691\n",
      "Epoch 40/250\n",
      "135/135 [==============================] - 0s 168us/step - loss: 4.6109 - binary_accuracy: 0.8691\n",
      "Epoch 41/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 4.6014 - binary_accuracy: 0.8691\n",
      "Epoch 42/250\n",
      "135/135 [==============================] - 0s 197us/step - loss: 4.6196 - binary_accuracy: 0.8691\n",
      "Epoch 43/250\n",
      "135/135 [==============================] - 0s 151us/step - loss: 4.5590 - binary_accuracy: 0.8691\n",
      "Epoch 44/250\n",
      "135/135 [==============================] - 0s 134us/step - loss: 4.4497 - binary_accuracy: 0.8691\n",
      "Epoch 45/250\n",
      "135/135 [==============================] - 0s 193us/step - loss: 4.4702 - binary_accuracy: 0.8691\n",
      "Epoch 46/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 4.4159 - binary_accuracy: 0.8691\n",
      "Epoch 47/250\n",
      "135/135 [==============================] - 0s 163us/step - loss: 4.3344 - binary_accuracy: 0.8691\n",
      "Epoch 48/250\n",
      "135/135 [==============================] - 0s 174us/step - loss: 4.3820 - binary_accuracy: 0.8691\n",
      "Epoch 49/250\n",
      "135/135 [==============================] - 0s 215us/step - loss: 4.2564 - binary_accuracy: 0.8691\n",
      "Epoch 50/250\n",
      "135/135 [==============================] - 0s 181us/step - loss: 4.2640 - binary_accuracy: 0.8691\n",
      "Epoch 51/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 4.2895 - binary_accuracy: 0.8691\n",
      "Epoch 52/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 4.2129 - binary_accuracy: 0.8691\n",
      "Epoch 53/250\n",
      "135/135 [==============================] - 0s 222us/step - loss: 4.1931 - binary_accuracy: 0.8691\n",
      "Epoch 54/250\n",
      "135/135 [==============================] - 0s 193us/step - loss: 4.0798 - binary_accuracy: 0.8691\n",
      "Epoch 55/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 4.0716 - binary_accuracy: 0.8691\n",
      "Epoch 56/250\n",
      "135/135 [==============================] - 0s 147us/step - loss: 4.1797 - binary_accuracy: 0.8691\n",
      "Epoch 57/250\n",
      "135/135 [==============================] - 0s 132us/step - loss: 3.8854 - binary_accuracy: 0.8691\n",
      "Epoch 58/250\n",
      "135/135 [==============================] - 0s 209us/step - loss: 4.0419 - binary_accuracy: 0.8667\n",
      "Epoch 59/250\n",
      "135/135 [==============================] - 0s 190us/step - loss: 3.9085 - binary_accuracy: 0.8667\n",
      "Epoch 60/250\n",
      "135/135 [==============================] - 0s 176us/step - loss: 4.0192 - binary_accuracy: 0.8667\n",
      "Epoch 61/250\n",
      "135/135 [==============================] - 0s 168us/step - loss: 3.9220 - binary_accuracy: 0.8667\n",
      "Epoch 62/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 3.8235 - binary_accuracy: 0.8667\n",
      "Epoch 63/250\n",
      "135/135 [==============================] - 0s 156us/step - loss: 3.8078 - binary_accuracy: 0.8667\n",
      "Epoch 64/250\n",
      "135/135 [==============================] - 0s 160us/step - loss: 3.8259 - binary_accuracy: 0.8667\n",
      "Epoch 65/250\n",
      "135/135 [==============================] - 0s 134us/step - loss: 3.7981 - binary_accuracy: 0.8691\n",
      "Epoch 66/250\n",
      "135/135 [==============================] - 0s 150us/step - loss: 3.7467 - binary_accuracy: 0.8667\n",
      "Epoch 67/250\n",
      "135/135 [==============================] - 0s 148us/step - loss: 3.7811 - binary_accuracy: 0.8667\n",
      "Epoch 68/250\n",
      "135/135 [==============================] - 0s 180us/step - loss: 3.7411 - binary_accuracy: 0.8691\n",
      "Epoch 69/250\n",
      "135/135 [==============================] - 0s 185us/step - loss: 3.7362 - binary_accuracy: 0.8691\n",
      "Epoch 70/250\n",
      "135/135 [==============================] - 0s 133us/step - loss: 3.6619 - binary_accuracy: 0.8691\n",
      "Epoch 71/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 3.5905 - binary_accuracy: 0.8667\n",
      "Epoch 72/250\n",
      "135/135 [==============================] - 0s 150us/step - loss: 3.6404 - binary_accuracy: 0.8716\n",
      "Epoch 73/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 3.6231 - binary_accuracy: 0.8691\n",
      "Epoch 74/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 175us/step - loss: 3.6126 - binary_accuracy: 0.8691\n",
      "Epoch 75/250\n",
      "135/135 [==============================] - 0s 167us/step - loss: 3.6048 - binary_accuracy: 0.8691\n",
      "Epoch 76/250\n",
      "135/135 [==============================] - 0s 146us/step - loss: 3.4735 - binary_accuracy: 0.8691\n",
      "Epoch 77/250\n",
      "135/135 [==============================] - 0s 198us/step - loss: 3.4629 - binary_accuracy: 0.8691\n",
      "Epoch 78/250\n",
      "135/135 [==============================] - 0s 188us/step - loss: 3.4718 - binary_accuracy: 0.8716\n",
      "Epoch 79/250\n",
      "135/135 [==============================] - 0s 195us/step - loss: 3.4808 - binary_accuracy: 0.8716\n",
      "Epoch 80/250\n",
      "135/135 [==============================] - 0s 191us/step - loss: 3.4509 - binary_accuracy: 0.8716\n",
      "Epoch 81/250\n",
      "135/135 [==============================] - 0s 215us/step - loss: 3.2964 - binary_accuracy: 0.8716\n",
      "Epoch 82/250\n",
      "135/135 [==============================] - 0s 177us/step - loss: 3.3726 - binary_accuracy: 0.8716\n",
      "Epoch 83/250\n",
      "135/135 [==============================] - 0s 165us/step - loss: 3.3216 - binary_accuracy: 0.8716\n",
      "Epoch 84/250\n",
      "135/135 [==============================] - 0s 182us/step - loss: 3.3617 - binary_accuracy: 0.8716\n",
      "Epoch 85/250\n",
      "135/135 [==============================] - 0s 156us/step - loss: 3.3028 - binary_accuracy: 0.8716\n",
      "Epoch 86/250\n",
      "135/135 [==============================] - 0s 186us/step - loss: 3.2926 - binary_accuracy: 0.8716\n",
      "Epoch 87/250\n",
      "135/135 [==============================] - 0s 192us/step - loss: 3.3972 - binary_accuracy: 0.8716\n",
      "Epoch 88/250\n",
      "135/135 [==============================] - 0s 227us/step - loss: 3.3089 - binary_accuracy: 0.8716\n",
      "Epoch 89/250\n",
      "135/135 [==============================] - 0s 209us/step - loss: 3.2234 - binary_accuracy: 0.8716\n",
      "Epoch 90/250\n",
      "135/135 [==============================] - 0s 224us/step - loss: 3.1956 - binary_accuracy: 0.8716\n",
      "Epoch 91/250\n",
      "135/135 [==============================] - 0s 171us/step - loss: 3.0695 - binary_accuracy: 0.8716\n",
      "Epoch 92/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 3.2819 - binary_accuracy: 0.8716\n",
      "Epoch 93/250\n",
      "135/135 [==============================] - 0s 175us/step - loss: 3.1998 - binary_accuracy: 0.8815\n",
      "Epoch 94/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 3.1206 - binary_accuracy: 0.8938\n",
      "Epoch 95/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 3.0849 - binary_accuracy: 0.8988\n",
      "Epoch 96/250\n",
      "135/135 [==============================] - 0s 224us/step - loss: 3.1148 - binary_accuracy: 0.9062\n",
      "Epoch 97/250\n",
      "135/135 [==============================] - 0s 173us/step - loss: 3.0618 - binary_accuracy: 0.9160\n",
      "Epoch 98/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 3.0662 - binary_accuracy: 0.9160\n",
      "Epoch 99/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 3.0597 - binary_accuracy: 0.9185\n",
      "Epoch 100/250\n",
      "135/135 [==============================] - 0s 200us/step - loss: 3.0916 - binary_accuracy: 0.9185\n",
      "Epoch 101/250\n",
      "135/135 [==============================] - 0s 174us/step - loss: 2.9682 - binary_accuracy: 0.9185\n",
      "Epoch 102/250\n",
      "135/135 [==============================] - 0s 173us/step - loss: 2.9410 - binary_accuracy: 0.9185\n",
      "Epoch 103/250\n",
      "135/135 [==============================] - 0s 138us/step - loss: 2.9775 - binary_accuracy: 0.9235\n",
      "Epoch 104/250\n",
      "135/135 [==============================] - 0s 182us/step - loss: 2.9747 - binary_accuracy: 0.9259\n",
      "Epoch 105/250\n",
      "135/135 [==============================] - 0s 167us/step - loss: 2.9953 - binary_accuracy: 0.9383\n",
      "Epoch 106/250\n",
      "135/135 [==============================] - 0s 181us/step - loss: 2.9629 - binary_accuracy: 0.9407\n",
      "Epoch 107/250\n",
      "135/135 [==============================] - 0s 156us/step - loss: 2.8192 - binary_accuracy: 0.9432\n",
      "Epoch 108/250\n",
      "135/135 [==============================] - 0s 149us/step - loss: 2.8696 - binary_accuracy: 0.9432\n",
      "Epoch 109/250\n",
      "135/135 [==============================] - 0s 169us/step - loss: 2.9043 - binary_accuracy: 0.9481\n",
      "Epoch 110/250\n",
      "135/135 [==============================] - 0s 146us/step - loss: 2.8741 - binary_accuracy: 0.9506\n",
      "Epoch 111/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 2.7927 - binary_accuracy: 0.9531\n",
      "Epoch 112/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 2.8190 - binary_accuracy: 0.9556\n",
      "Epoch 113/250\n",
      "135/135 [==============================] - 0s 145us/step - loss: 2.8142 - binary_accuracy: 0.9556\n",
      "Epoch 114/250\n",
      "135/135 [==============================] - 0s 160us/step - loss: 2.7023 - binary_accuracy: 0.9556\n",
      "Epoch 115/250\n",
      "135/135 [==============================] - 0s 160us/step - loss: 2.8083 - binary_accuracy: 0.9556\n",
      "Epoch 116/250\n",
      "135/135 [==============================] - 0s 150us/step - loss: 2.7264 - binary_accuracy: 0.9556\n",
      "Epoch 117/250\n",
      "135/135 [==============================] - 0s 165us/step - loss: 2.7158 - binary_accuracy: 0.9556\n",
      "Epoch 118/250\n",
      "135/135 [==============================] - 0s 143us/step - loss: 2.7782 - binary_accuracy: 0.9556\n",
      "Epoch 119/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 2.7148 - binary_accuracy: 0.9556\n",
      "Epoch 120/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 2.6914 - binary_accuracy: 0.9580\n",
      "Epoch 121/250\n",
      "135/135 [==============================] - 0s 157us/step - loss: 2.6938 - binary_accuracy: 0.9580\n",
      "Epoch 122/250\n",
      "135/135 [==============================] - 0s 136us/step - loss: 2.6116 - binary_accuracy: 0.9605\n",
      "Epoch 123/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 2.5990 - binary_accuracy: 0.9605\n",
      "Epoch 124/250\n",
      "135/135 [==============================] - 0s 155us/step - loss: 2.6455 - binary_accuracy: 0.9605\n",
      "Epoch 125/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 2.5875 - binary_accuracy: 0.9605\n",
      "Epoch 126/250\n",
      "135/135 [==============================] - 0s 163us/step - loss: 2.5800 - binary_accuracy: 0.9605\n",
      "Epoch 127/250\n",
      "135/135 [==============================] - 0s 165us/step - loss: 2.5815 - binary_accuracy: 0.9630\n",
      "Epoch 128/250\n",
      "135/135 [==============================] - 0s 157us/step - loss: 2.6265 - binary_accuracy: 0.9654\n",
      "Epoch 129/250\n",
      "135/135 [==============================] - 0s 190us/step - loss: 2.6005 - binary_accuracy: 0.9654\n",
      "Epoch 130/250\n",
      "135/135 [==============================] - 0s 157us/step - loss: 2.5369 - binary_accuracy: 0.9679\n",
      "Epoch 131/250\n",
      "135/135 [==============================] - 0s 182us/step - loss: 2.5855 - binary_accuracy: 0.9679\n",
      "Epoch 132/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 2.5715 - binary_accuracy: 0.9679\n",
      "Epoch 133/250\n",
      "135/135 [==============================] - 0s 182us/step - loss: 2.5394 - binary_accuracy: 0.9679\n",
      "Epoch 134/250\n",
      "135/135 [==============================] - 0s 147us/step - loss: 2.4446 - binary_accuracy: 0.9679\n",
      "Epoch 135/250\n",
      "135/135 [==============================] - 0s 157us/step - loss: 2.4634 - binary_accuracy: 0.9704\n",
      "Epoch 136/250\n",
      "135/135 [==============================] - 0s 169us/step - loss: 2.5323 - binary_accuracy: 0.9728\n",
      "Epoch 137/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 2.4158 - binary_accuracy: 0.9728\n",
      "Epoch 138/250\n",
      "135/135 [==============================] - 0s 171us/step - loss: 2.4677 - binary_accuracy: 0.9753\n",
      "Epoch 139/250\n",
      "135/135 [==============================] - 0s 173us/step - loss: 2.4486 - binary_accuracy: 0.9753\n",
      "Epoch 140/250\n",
      "135/135 [==============================] - 0s 169us/step - loss: 2.4173 - binary_accuracy: 0.9753\n",
      "Epoch 141/250\n",
      "135/135 [==============================] - 0s 170us/step - loss: 2.4035 - binary_accuracy: 0.9753\n",
      "Epoch 142/250\n",
      "135/135 [==============================] - 0s 148us/step - loss: 2.3390 - binary_accuracy: 0.9728\n",
      "Epoch 143/250\n",
      "135/135 [==============================] - 0s 187us/step - loss: 2.2788 - binary_accuracy: 0.9753\n",
      "Epoch 144/250\n",
      "135/135 [==============================] - 0s 152us/step - loss: 2.2537 - binary_accuracy: 0.9753\n",
      "Epoch 145/250\n",
      "135/135 [==============================] - 0s 167us/step - loss: 2.1973 - binary_accuracy: 0.9753\n",
      "Epoch 146/250\n",
      "135/135 [==============================] - 0s 164us/step - loss: 2.2764 - binary_accuracy: 0.9753\n",
      "Epoch 147/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 159us/step - loss: 2.2046 - binary_accuracy: 0.9753\n",
      "Epoch 148/250\n",
      "135/135 [==============================] - 0s 182us/step - loss: 2.2367 - binary_accuracy: 0.9753\n",
      "Epoch 149/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 2.2147 - binary_accuracy: 0.9753\n",
      "Epoch 150/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 2.2699 - binary_accuracy: 0.9753\n",
      "Epoch 151/250\n",
      "135/135 [==============================] - 0s 163us/step - loss: 2.2065 - binary_accuracy: 0.9753\n",
      "Epoch 152/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 2.2410 - binary_accuracy: 0.9753\n",
      "Epoch 153/250\n",
      "135/135 [==============================] - 0s 165us/step - loss: 2.2098 - binary_accuracy: 0.9753\n",
      "Epoch 154/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 2.1972 - binary_accuracy: 0.9753\n",
      "Epoch 155/250\n",
      "135/135 [==============================] - 0s 140us/step - loss: 2.2046 - binary_accuracy: 0.9753\n",
      "Epoch 156/250\n",
      "135/135 [==============================] - 0s 189us/step - loss: 2.1670 - binary_accuracy: 0.9778\n",
      "Epoch 157/250\n",
      "135/135 [==============================] - 0s 163us/step - loss: 2.1293 - binary_accuracy: 0.9778\n",
      "Epoch 158/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 2.1709 - binary_accuracy: 0.9778\n",
      "Epoch 159/250\n",
      "135/135 [==============================] - 0s 174us/step - loss: 2.1956 - binary_accuracy: 0.9778\n",
      "Epoch 160/250\n",
      "135/135 [==============================] - 0s 173us/step - loss: 2.1060 - binary_accuracy: 0.9802\n",
      "Epoch 161/250\n",
      "135/135 [==============================] - 0s 168us/step - loss: 2.1140 - binary_accuracy: 0.9802\n",
      "Epoch 162/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 2.0710 - binary_accuracy: 0.9802\n",
      "Epoch 163/250\n",
      "135/135 [==============================] - 0s 175us/step - loss: 2.0895 - binary_accuracy: 0.9802\n",
      "Epoch 164/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 2.0765 - binary_accuracy: 0.9802\n",
      "Epoch 165/250\n",
      "135/135 [==============================] - 0s 192us/step - loss: 2.1102 - binary_accuracy: 0.9802\n",
      "Epoch 166/250\n",
      "135/135 [==============================] - 0s 144us/step - loss: 2.0905 - binary_accuracy: 0.9802\n",
      "Epoch 167/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 2.0868 - binary_accuracy: 0.9802\n",
      "Epoch 168/250\n",
      "135/135 [==============================] - 0s 179us/step - loss: 2.0406 - binary_accuracy: 0.9802\n",
      "Epoch 169/250\n",
      "135/135 [==============================] - 0s 155us/step - loss: 2.0263 - binary_accuracy: 0.9802\n",
      "Epoch 170/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 1.9760 - binary_accuracy: 0.9802\n",
      "Epoch 171/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 1.9821 - binary_accuracy: 0.9802\n",
      "Epoch 172/250\n",
      "135/135 [==============================] - 0s 147us/step - loss: 2.0003 - binary_accuracy: 0.9802\n",
      "Epoch 173/250\n",
      "135/135 [==============================] - 0s 180us/step - loss: 1.9359 - binary_accuracy: 0.9802\n",
      "Epoch 174/250\n",
      "135/135 [==============================] - 0s 169us/step - loss: 1.8907 - binary_accuracy: 0.9827\n",
      "Epoch 175/250\n",
      "135/135 [==============================] - 0s 151us/step - loss: 1.8439 - binary_accuracy: 0.9827\n",
      "Epoch 176/250\n",
      "135/135 [==============================] - 0s 178us/step - loss: 1.8913 - binary_accuracy: 0.9827\n",
      "Epoch 177/250\n",
      "135/135 [==============================] - 0s 141us/step - loss: 1.9301 - binary_accuracy: 0.9827\n",
      "Epoch 178/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 1.9003 - binary_accuracy: 0.9827\n",
      "Epoch 179/250\n",
      "135/135 [==============================] - 0s 160us/step - loss: 1.8873 - binary_accuracy: 0.9827\n",
      "Epoch 180/250\n",
      "135/135 [==============================] - 0s 169us/step - loss: 1.8707 - binary_accuracy: 0.9827\n",
      "Epoch 181/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 1.8869 - binary_accuracy: 0.9827\n",
      "Epoch 182/250\n",
      "135/135 [==============================] - 0s 166us/step - loss: 1.8556 - binary_accuracy: 0.9827\n",
      "Epoch 183/250\n",
      "135/135 [==============================] - 0s 182us/step - loss: 1.8462 - binary_accuracy: 0.9827\n",
      "Epoch 184/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 1.8718 - binary_accuracy: 0.9827\n",
      "Epoch 185/250\n",
      "135/135 [==============================] - 0s 181us/step - loss: 1.8016 - binary_accuracy: 0.9827\n",
      "Epoch 186/250\n",
      "135/135 [==============================] - 0s 147us/step - loss: 1.7760 - binary_accuracy: 0.9827\n",
      "Epoch 187/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 1.8286 - binary_accuracy: 0.9827\n",
      "Epoch 188/250\n",
      "135/135 [==============================] - 0s 172us/step - loss: 1.7604 - binary_accuracy: 0.9827\n",
      "Epoch 189/250\n",
      "135/135 [==============================] - 0s 148us/step - loss: 1.7678 - binary_accuracy: 0.9827\n",
      "Epoch 190/250\n",
      "135/135 [==============================] - 0s 191us/step - loss: 1.8223 - binary_accuracy: 0.9827\n",
      "Epoch 191/250\n",
      "135/135 [==============================] - 0s 149us/step - loss: 1.8057 - binary_accuracy: 0.9827\n",
      "Epoch 192/250\n",
      "135/135 [==============================] - 0s 165us/step - loss: 1.7620 - binary_accuracy: 0.9827\n",
      "Epoch 193/250\n",
      "135/135 [==============================] - 0s 151us/step - loss: 1.8216 - binary_accuracy: 0.9827\n",
      "Epoch 194/250\n",
      "135/135 [==============================] - 0s 155us/step - loss: 1.7225 - binary_accuracy: 0.9827\n",
      "Epoch 195/250\n",
      "135/135 [==============================] - 0s 186us/step - loss: 1.6690 - binary_accuracy: 0.9827\n",
      "Epoch 196/250\n",
      "135/135 [==============================] - 0s 155us/step - loss: 1.7411 - binary_accuracy: 0.9827\n",
      "Epoch 197/250\n",
      "135/135 [==============================] - 0s 197us/step - loss: 1.7364 - binary_accuracy: 0.9827\n",
      "Epoch 198/250\n",
      "135/135 [==============================] - 0s 156us/step - loss: 1.7062 - binary_accuracy: 0.9827\n",
      "Epoch 199/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 1.6204 - binary_accuracy: 0.9827\n",
      "Epoch 200/250\n",
      "135/135 [==============================] - 0s 156us/step - loss: 1.7311 - binary_accuracy: 0.9827\n",
      "Epoch 201/250\n",
      "135/135 [==============================] - 0s 143us/step - loss: 1.7049 - binary_accuracy: 0.9827\n",
      "Epoch 202/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 1.6638 - binary_accuracy: 0.9827\n",
      "Epoch 203/250\n",
      "135/135 [==============================] - 0s 172us/step - loss: 1.6441 - binary_accuracy: 0.9827\n",
      "Epoch 204/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 1.6363 - binary_accuracy: 0.9827\n",
      "Epoch 205/250\n",
      "135/135 [==============================] - 0s 170us/step - loss: 1.5969 - binary_accuracy: 0.9827\n",
      "Epoch 206/250\n",
      "135/135 [==============================] - 0s 142us/step - loss: 1.6451 - binary_accuracy: 0.9827\n",
      "Epoch 207/250\n",
      "135/135 [==============================] - 0s 145us/step - loss: 1.6346 - binary_accuracy: 0.9827\n",
      "Epoch 208/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 1.6527 - binary_accuracy: 0.9827\n",
      "Epoch 209/250\n",
      "135/135 [==============================] - 0s 157us/step - loss: 1.6246 - binary_accuracy: 0.9827\n",
      "Epoch 210/250\n",
      "135/135 [==============================] - 0s 140us/step - loss: 1.6048 - binary_accuracy: 0.9827\n",
      "Epoch 211/250\n",
      "135/135 [==============================] - 0s 144us/step - loss: 1.6174 - binary_accuracy: 0.9827\n",
      "Epoch 212/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 1.5770 - binary_accuracy: 0.9827\n",
      "Epoch 213/250\n",
      "135/135 [==============================] - 0s 174us/step - loss: 1.5761 - binary_accuracy: 0.9827\n",
      "Epoch 214/250\n",
      "135/135 [==============================] - 0s 186us/step - loss: 1.5937 - binary_accuracy: 0.9827\n",
      "Epoch 215/250\n",
      "135/135 [==============================] - 0s 151us/step - loss: 1.5805 - binary_accuracy: 0.9827\n",
      "Epoch 216/250\n",
      "135/135 [==============================] - 0s 163us/step - loss: 1.5415 - binary_accuracy: 0.9827\n",
      "Epoch 217/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 1.5539 - binary_accuracy: 0.9852\n",
      "Epoch 218/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 1.5585 - binary_accuracy: 0.9852\n",
      "Epoch 219/250\n",
      "135/135 [==============================] - 0s 191us/step - loss: 1.5228 - binary_accuracy: 0.9852\n",
      "Epoch 220/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 161us/step - loss: 1.5438 - binary_accuracy: 0.9852\n",
      "Epoch 221/250\n",
      "135/135 [==============================] - 0s 153us/step - loss: 1.4875 - binary_accuracy: 0.9827\n",
      "Epoch 222/250\n",
      "135/135 [==============================] - 0s 169us/step - loss: 1.5102 - binary_accuracy: 0.9852\n",
      "Epoch 223/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 1.4431 - binary_accuracy: 0.9852\n",
      "Epoch 224/250\n",
      "135/135 [==============================] - 0s 155us/step - loss: 1.5068 - binary_accuracy: 0.9852\n",
      "Epoch 225/250\n",
      "135/135 [==============================] - 0s 158us/step - loss: 1.5036 - binary_accuracy: 0.9852\n",
      "Epoch 226/250\n",
      "135/135 [==============================] - 0s 178us/step - loss: 1.5193 - binary_accuracy: 0.9852\n",
      "Epoch 227/250\n",
      "135/135 [==============================] - 0s 142us/step - loss: 1.5160 - binary_accuracy: 0.9852\n",
      "Epoch 228/250\n",
      "135/135 [==============================] - 0s 125us/step - loss: 1.4537 - binary_accuracy: 0.9852\n",
      "Epoch 229/250\n",
      "135/135 [==============================] - 0s 150us/step - loss: 1.4843 - binary_accuracy: 0.9852\n",
      "Epoch 230/250\n",
      "135/135 [==============================] - 0s 171us/step - loss: 1.4507 - binary_accuracy: 0.9852\n",
      "Epoch 231/250\n",
      "135/135 [==============================] - 0s 147us/step - loss: 1.4769 - binary_accuracy: 0.9852\n",
      "Epoch 232/250\n",
      "135/135 [==============================] - 0s 139us/step - loss: 1.4216 - binary_accuracy: 0.9852\n",
      "Epoch 233/250\n",
      "135/135 [==============================] - 0s 180us/step - loss: 1.4497 - binary_accuracy: 0.9852\n",
      "Epoch 234/250\n",
      "135/135 [==============================] - 0s 160us/step - loss: 1.4135 - binary_accuracy: 0.9852\n",
      "Epoch 235/250\n",
      "135/135 [==============================] - 0s 190us/step - loss: 1.4495 - binary_accuracy: 0.9852\n",
      "Epoch 236/250\n",
      "135/135 [==============================] - 0s 137us/step - loss: 1.4153 - binary_accuracy: 0.9852\n",
      "Epoch 237/250\n",
      "135/135 [==============================] - 0s 141us/step - loss: 1.3831 - binary_accuracy: 0.9852\n",
      "Epoch 238/250\n",
      "135/135 [==============================] - 0s 178us/step - loss: 1.3863 - binary_accuracy: 0.9852\n",
      "Epoch 239/250\n",
      "135/135 [==============================] - 0s 169us/step - loss: 1.3719 - binary_accuracy: 0.9852\n",
      "Epoch 240/250\n",
      "135/135 [==============================] - 0s 188us/step - loss: 1.3375 - binary_accuracy: 0.9852\n",
      "Epoch 241/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 1.4107 - binary_accuracy: 0.9852\n",
      "Epoch 242/250\n",
      "135/135 [==============================] - 0s 139us/step - loss: 1.3820 - binary_accuracy: 0.9852\n",
      "Epoch 243/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 1.3613 - binary_accuracy: 0.9852\n",
      "Epoch 244/250\n",
      "135/135 [==============================] - 0s 159us/step - loss: 1.3395 - binary_accuracy: 0.9852\n",
      "Epoch 245/250\n",
      "135/135 [==============================] - 0s 182us/step - loss: 1.3014 - binary_accuracy: 0.9852\n",
      "Epoch 246/250\n",
      "135/135 [==============================] - 0s 154us/step - loss: 1.3673 - binary_accuracy: 0.9852\n",
      "Epoch 247/250\n",
      "135/135 [==============================] - 0s 165us/step - loss: 1.3569 - binary_accuracy: 0.9852\n",
      "Epoch 248/250\n",
      "135/135 [==============================] - 0s 161us/step - loss: 1.3005 - binary_accuracy: 0.9852\n",
      "Epoch 249/250\n",
      "135/135 [==============================] - 0s 162us/step - loss: 1.3391 - binary_accuracy: 0.9852\n",
      "Epoch 250/250\n",
      "135/135 [==============================] - 0s 170us/step - loss: 1.3066 - binary_accuracy: 0.9852\n",
      "Pruning neurons...\n",
      "No neurons detected for pruning\n"
     ]
    }
   ],
   "source": [
    "sofnn.organize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sofnn.network.neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21204683, 0.7854857 , 0.00246747],\n",
       "       [0.272288  , 0.7174145 , 0.01029748],\n",
       "       [0.22003397, 0.77694404, 0.00302197],\n",
       "       [0.2842181 , 0.7023656 , 0.01341628],\n",
       "       [0.28714874, 0.69853896, 0.01431225],\n",
       "       [0.24526753, 0.7491703 , 0.00556221],\n",
       "       [0.21800086, 0.7791278 , 0.00287141],\n",
       "       [0.24924703, 0.7446505 , 0.00610254],\n",
       "       [0.27465296, 0.71449256, 0.01085454],\n",
       "       [0.25545374, 0.7375053 , 0.00704099],\n",
       "       [0.24141243, 0.75350726, 0.00508033],\n",
       "       [0.2088749 , 0.7888519 , 0.0022732 ],\n",
       "       [0.2304319 , 0.7656625 , 0.00390563],\n",
       "       [0.22723606, 0.76915145, 0.00361254],\n",
       "       [0.27411488, 0.71515983, 0.01072533],\n",
       "       [0.29049012, 0.6941041 , 0.01540576],\n",
       "       [0.21537535, 0.78193796, 0.0026867 ],\n",
       "       [0.23897628, 0.75622827, 0.00479549],\n",
       "       [0.23346236, 0.7623348 , 0.00420281],\n",
       "       [0.30002737, 0.68096346, 0.01900921],\n",
       "       [0.29321903, 0.69042087, 0.0163601 ],\n",
       "       [0.24900754, 0.7449238 , 0.00606873],\n",
       "       [0.2907892 , 0.6937031 , 0.01550759],\n",
       "       [0.22563587, 0.77089095, 0.00347321],\n",
       "       [0.24141243, 0.75350726, 0.00508033],\n",
       "       [0.22647153, 0.7699831 , 0.00354537],\n",
       "       [0.21909682, 0.7779515 , 0.00295173],\n",
       "       [0.2859686 , 0.7000867 , 0.01394461],\n",
       "       [0.29236642, 0.69157785, 0.01605575],\n",
       "       [0.25778237, 0.73479176, 0.00742587],\n",
       "       [0.22585335, 0.7706548 , 0.00349187],\n",
       "       [0.22160153, 0.77525574, 0.00314273],\n",
       "       [0.2826361 , 0.7044083 , 0.01295563],\n",
       "       [0.21761642, 0.7795398 , 0.00284369],\n",
       "       [0.23593737, 0.75960237, 0.00446024],\n",
       "       [0.23497562, 0.7606658 , 0.00435859],\n",
       "       [0.21561122, 0.781686  , 0.00270285],\n",
       "       [0.23982793, 0.7552787 , 0.00489339],\n",
       "       [0.23268117, 0.7631945 , 0.00412434],\n",
       "       [0.30961734, 0.66686887, 0.02351386],\n",
       "       [0.2823121 , 0.7048247 , 0.0128632 ],\n",
       "       [0.22694956, 0.7694631 , 0.00358724],\n",
       "       [0.2233026 , 0.77341884, 0.00327855],\n",
       "       [0.24621949, 0.7480932 , 0.00568737],\n",
       "       [0.24721082, 0.74696887, 0.00582041],\n",
       "       [0.2263517 , 0.7701134 , 0.00353494],\n",
       "       [0.2578938 , 0.7346614 , 0.00744476],\n",
       "       [0.26400542, 0.7274429 , 0.0085516 ],\n",
       "       [0.29548785, 0.68731356, 0.01719853],\n",
       "       [0.21864153, 0.77844036, 0.00291813],\n",
       "       [0.29290667, 0.69084543, 0.01624794],\n",
       "       [0.22045434, 0.77649176, 0.00305395],\n",
       "       [0.28976858, 0.6950685 , 0.01516284],\n",
       "       [0.24355339, 0.7511035 , 0.00534309],\n",
       "       [0.27893925, 0.70912266, 0.01193816],\n",
       "       [0.28170687, 0.7056009 , 0.01269226],\n",
       "       [0.27481514, 0.7142911 , 0.01089378],\n",
       "       [0.21281788, 0.7846652 , 0.00251682],\n",
       "       [0.24113931, 0.75381297, 0.00504766],\n",
       "       [0.2593497 , 0.73295456, 0.0076957 ],\n",
       "       [0.27284306, 0.7167312 , 0.01042574],\n",
       "       [0.2915044 , 0.6927417 , 0.01575382],\n",
       "       [0.23268716, 0.7631879 , 0.00412494],\n",
       "       [0.22540486, 0.7711416 , 0.0034535 ],\n",
       "       [0.22317797, 0.77355355, 0.00326842],\n",
       "       [0.28468263, 0.70176286, 0.01355454],\n",
       "       [0.23555918, 0.7600208 , 0.00442002],\n",
       "       [0.27420235, 0.7150514 , 0.01074624],\n",
       "       [0.24274433, 0.7520133 , 0.00524239],\n",
       "       [0.20879501, 0.78893656, 0.00226848],\n",
       "       [0.29655296, 0.68584013, 0.01760694],\n",
       "       [0.23185532, 0.76410186, 0.00404281],\n",
       "       [0.21393302, 0.78347725, 0.0025897 ],\n",
       "       [0.22367258, 0.77301866, 0.00330876],\n",
       "       [0.2128681 , 0.7846119 , 0.00252006],\n",
       "       [0.2381677 , 0.7571281 , 0.00470416],\n",
       "       [0.24549599, 0.748912  , 0.00559202],\n",
       "       [0.2526731 , 0.7407214 , 0.00660541],\n",
       "       [0.30348778, 0.6759919 , 0.02052027],\n",
       "       [0.30827206, 0.66890866, 0.02281929],\n",
       "       [0.21754569, 0.7796157 , 0.00283861],\n",
       "       [0.24975662, 0.74406826, 0.00617507],\n",
       "       [0.23559965, 0.7599761 , 0.00442431],\n",
       "       [0.24422291, 0.75034934, 0.00542773],\n",
       "       [0.23461184, 0.7610675 , 0.00432068],\n",
       "       [0.2377369 , 0.757607  , 0.00465614],\n",
       "       [0.24223392, 0.7525864 , 0.00517974],\n",
       "       [0.2624841 , 0.7292532 , 0.00826268],\n",
       "       [0.23826498, 0.75702   , 0.00471506],\n",
       "       [0.24507016, 0.7493932 , 0.00553658],\n",
       "       [0.26137143, 0.7305714 , 0.00805712],\n",
       "       [0.28124726, 0.70618874, 0.01256393],\n",
       "       [0.21176815, 0.7857821 , 0.00244984],\n",
       "       [0.2960714 , 0.6865074 , 0.0174211 ],\n",
       "       [0.23744816, 0.7579276 , 0.0046242 ],\n",
       "       [0.27570722, 0.7131808 , 0.011112  ],\n",
       "       [0.2007577 , 0.7974072 , 0.00183512],\n",
       "       [0.2928308 , 0.6909484 , 0.0162208 ],\n",
       "       [0.23089333, 0.765157  , 0.00394964],\n",
       "       [0.23467083, 0.76100236, 0.0043268 ],\n",
       "       [0.19486666, 0.8035687 , 0.00156465],\n",
       "       [0.24810913, 0.7459475 , 0.00594339],\n",
       "       [0.23029159, 0.76581603, 0.00389233],\n",
       "       [0.22227798, 0.7745259 , 0.00319614],\n",
       "       [0.22977759, 0.76637846, 0.00384396],\n",
       "       [0.22500032, 0.77158046, 0.00341921],\n",
       "       [0.2469685 , 0.74724394, 0.00578763],\n",
       "       [0.30292442, 0.67680955, 0.02026602],\n",
       "       [0.27487335, 0.7142188 , 0.01090789],\n",
       "       [0.27025446, 0.7199053 , 0.00984022],\n",
       "       [0.24478474, 0.74971557, 0.00549969],\n",
       "       [0.23407856, 0.76165587, 0.00426563],\n",
       "       [0.26724753, 0.7235534 , 0.00919901],\n",
       "       [0.27497137, 0.7140969 , 0.0109317 ],\n",
       "       [0.27975702, 0.7080866 , 0.01215637],\n",
       "       [0.25269356, 0.740698  , 0.00660852],\n",
       "       [0.26097122, 0.7310444 , 0.00798435],\n",
       "       [0.2217711 , 0.77507275, 0.00315604],\n",
       "       [0.25557896, 0.7373598 , 0.00706122],\n",
       "       [0.28653625, 0.69934344, 0.01412027],\n",
       "       [0.25516406, 0.7378416 , 0.00699442],\n",
       "       [0.2318039 , 0.76415837, 0.00403778],\n",
       "       [0.22275944, 0.77400583, 0.00323463],\n",
       "       [0.24594566, 0.7484033 , 0.00565111],\n",
       "       [0.27675575, 0.7118704 , 0.01137383],\n",
       "       [0.27466068, 0.71448296, 0.01085641],\n",
       "       [0.2639076 , 0.7275596 , 0.00853275],\n",
       "       [0.27431074, 0.71491706, 0.0107722 ],\n",
       "       [0.24976787, 0.7440555 , 0.00617667],\n",
       "       [0.26193503, 0.72990435, 0.00816064],\n",
       "       [0.23599085, 0.75954324, 0.00446595],\n",
       "       [0.22960506, 0.766567  , 0.00382785],\n",
       "       [0.22967596, 0.76648957, 0.00383447],\n",
       "       [0.22618777, 0.7702915 , 0.00352072],\n",
       "       [0.29191232, 0.6921917 , 0.01589597]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = sofnn.model.predict(network.X_train)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30517409136009305"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_rmae = mean_squared_error(network.y_train, preds)\n",
    "E_rmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create duplicate model and clone weights\n",
    "prune_model = sofnn.duplicate_model()\n",
    "act_weights = sofnn.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15210323, 0.15168682, 0.12369449])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_E = []\n",
    "for neur in range(network.neurons):\n",
    "    # reset prune model weights to actual weights\n",
    "    prune_model.set_weights(act_weights)\n",
    "\n",
    "    # get current prune weights\n",
    "    w = prune_model.get_weights()\n",
    "    a = w[2]\n",
    "    # zero our i neuron column in weight vector\n",
    "    a[:, neur] = 0\n",
    "    prune_model.set_weights(w)\n",
    "\n",
    "    # predict values with new zeroed out weights\n",
    "    neur_pred = prune_model.predict(network.X_test)\n",
    "    neur_rmae = mean_absolute_error(network.y_test, neur_pred)\n",
    "\n",
    "    # append difference in rmse and new prediction rmse\n",
    "    delta_E.append(neur_rmae - E_rmae)\n",
    "delta_E = np.array(delta_E)\n",
    "delta_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2593979776560791"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose max of tolerance or threshold limit\n",
    "E = max(sofnn._prune_tol * E_rmae, sofnn._k_mae)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4318438596931504\n",
      "0.4327395782975572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over each neuron in ascending importance\n",
    "# and prune until hit \"important\" neuron\n",
    "deleted = []\n",
    "# for each neuron up to second most important\n",
    "for neur in delta_E.argsort()[:-1]:\n",
    "    # reset prune model weights to actual weights\n",
    "    prune_model.set_weights(act_weights)\n",
    "\n",
    "    # get current prune weights\n",
    "    w = prune_model.get_weights()\n",
    "    a = w[2]\n",
    "    # zero out previous deleted neurons\n",
    "    for delete in deleted:\n",
    "        a[:, delete] = 0\n",
    "    # zero our i neuron column in weight vector\n",
    "    a[:, neur] = 0\n",
    "    prune_model.set_weights(w)\n",
    "\n",
    "    # predict values with new zeroed out weights\n",
    "    neur_pred = prune_model.predict(network.X_train)\n",
    "    E_rmae_del = mean_absolute_error(network.y_train, neur_pred)\n",
    "    \n",
    "    print(E_rmae_del)\n",
    "\n",
    "    # if E_mae_del < E\n",
    "    # delete neuron\n",
    "    if E_rmae_del < E:\n",
    "        deleted.append(neur)\n",
    "deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2593979776560791"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[6.5725527, 5.4399815, 6.5725527],\n",
       "        [2.9785914, 2.7076423, 2.7076423],\n",
       "        [5.400637 , 3.908422 , 3.908422 ],\n",
       "        [1.7979747, 1.0074292, 1.2022222]], dtype=float32),\n",
       " array([[4.013405 , 3.7405446, 4.013405 ],\n",
       "        [4.0589285, 3.869836 , 3.869836 ],\n",
       "        [3.9257298, 3.7546628, 3.7546628],\n",
       "        [4.036143 , 3.7209027, 2.6237717]], dtype=float32),\n",
       " array([[-0.05574143,  0.        ,  1.        ],\n",
       "        [-0.02378742,  0.        ,  1.        ],\n",
       "        [-0.01280571,  0.        ,  1.        ],\n",
       "        [-0.14460018,  0.        ,  1.        ],\n",
       "        [-0.12933777,  0.        ,  1.        ]], dtype=float32),\n",
       " array([[ 0.03643201,  0.26109552, -0.7407877 ]], dtype=float32),\n",
       " array([-0.00394318,  0.01967439, -0.00908445], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = prune_model.get_weights()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[6.5725527, 6.5725527],\n",
       "        [2.9785914, 2.7076423],\n",
       "        [5.400637 , 3.908422 ],\n",
       "        [1.7979747, 1.2022222]], dtype=float32), array([[4.013405 , 4.013405 ],\n",
       "        [4.0589285, 3.869836 ],\n",
       "        [3.9257298, 3.7546628],\n",
       "        [4.036143 , 2.6237717]], dtype=float32), array([[-0.05574143,  1.        ],\n",
       "        [-0.02378742,  1.        ],\n",
       "        [-0.01280571,  1.        ],\n",
       "        [-0.14460018,  1.        ],\n",
       "        [-0.12933777,  1.        ]], dtype=float32), array([[ 0.03643201,  0.26109552, -0.7407877 ]], dtype=float32), array([-0.00394318,  0.01967439, -0.00908445], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, weight in enumerate(w[:3]):\n",
    "    w[i] = np.delete(weight, deleted, axis=-1)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, 2, 3]'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_test = [1,2,3]\n",
    "\n",
    "'{}'.format(w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neurons successfully pruned! - 3 current neurons...\n"
     ]
    }
   ],
   "source": [
    "print('{} neurons successfully pruned! - {} current neurons...'.\n",
    "                  format(len(deleted), network.neurons))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current weights\n",
    "c_curr, s_curr = network.get_layer_weights(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Neuron Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input values and fuzzy weights\n",
    "x = network.X_train\n",
    "c, s = network.get_layer_weights(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Dist Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get input values and fuzzy weights\n",
    "x = network.X_train\n",
    "samples = x.shape[0]\n",
    "c, s = network.get_layer_weights(1)\n",
    "\n",
    "# align x and c and assert matching dims\n",
    "aligned_x = x.repeat(network.neurons). \\\n",
    "    reshape(x.shape + (network.neurons,))\n",
    "aligned_c = c.repeat(samples).reshape((samples,) + c.shape)\n",
    "assert aligned_x.shape == aligned_c.shape\n",
    "\n",
    "min_dist = np.abs(aligned_x - aligned_c).mean(axis=0)\n",
    "min_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimum distance across neurons\n",
    "# and arg-min for neuron with lowest distance\n",
    "dist_vec = min_dist.min(axis=-1)\n",
    "min_neurs = min_dist.argmin(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.22395482, 1.66317437, 2.15747145, 2.78227219])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_neurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get min c and s weights\n",
    "c_min = c[:, min_neurs].diagonal()\n",
    "s_min = s[:, min_neurs].diagonal()\n",
    "assert c_min.shape == s_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_thresh = 1\n",
    "# set threshold distance as factor of mean\n",
    "# value for each feature across samples\n",
    "kd_i = x.mean(axis=0) * dist_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final weight vectors\n",
    "ck = np.where(dist_vec <= kd_i, c_min, x.mean(axis=0))\n",
    "sk = np.where(dist_vec <= kd_i, s_min, dist_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.2326479 , 2.67471886, 5.23959303, 1.20518519])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.88828325, 3.87935758, 4.06668282, 2.78227219])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand dim for stacking\n",
    "ck = np.expand_dims(ck, axis=-1)\n",
    "sk = np.expand_dims(sk, axis=-1)\n",
    "c_new = np.hstack((c_curr, ck))\n",
    "s_new = np.hstack((s_curr, sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2326479 ],\n",
       "       [2.67471886],\n",
       "       [5.23959303],\n",
       "       [1.20518519]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.88828325],\n",
       "       [3.87935758],\n",
       "       [4.06668282],\n",
       "       [2.78227219]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2326479 , 6.35563231, 6.2326479 ],\n",
       "       [2.67471886, 2.79995608, 2.67471886],\n",
       "       [4.84236383, 5.23959303, 5.23959303],\n",
       "       [1.86366856, 1.84255338, 1.20518519]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.232648 , 6.3556323],\n",
       "       [2.6747189, 2.799956 ],\n",
       "       [4.842364 , 5.239593 ],\n",
       "       [1.8636686, 1.8425534]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8882833, 4.092967 ],\n",
       "       [3.8793576, 4.101973 ],\n",
       "       [3.9268997, 4.066683 ],\n",
       "       [3.9271975, 4.0689926]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.88828325, 4.09296703, 3.88828325],\n",
       "       [3.87935758, 4.10197306, 3.87935758],\n",
       "       [3.92689967, 4.06668282, 4.06668282],\n",
       "       [3.92719746, 4.06899261, 2.78227219]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Inputs (InputLayer)             (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FuzzyRules (FuzzyLayer)         (None, 2)            16          Inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Normalization (NormalizedLayer) (None, 2)            0           FuzzyRules[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weights (WeightedLayer)         (None, 2)            10          Inputs[0][0]                     \n",
      "                                                                 Normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RawOutput (OutputLayer)         (None, 1)            0           Weights[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Dense)                 (None, 3)            6           RawOutput[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod2 = sofnn.duplicate_model()\n",
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[6.232648 , 6.3556323],\n",
       "        [2.6747189, 2.799956 ],\n",
       "        [4.842364 , 5.239593 ],\n",
       "        [1.8636686, 1.8425534]], dtype=float32), array([[3.8882833, 4.092967 ],\n",
       "        [3.8793576, 4.101973 ],\n",
       "        [3.9268997, 4.066683 ],\n",
       "        [3.9271975, 4.0689926]], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.get_layer_weights(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_test.get_layer('FuzzyRules').set_weights([c_new, s_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Inputs (InputLayer)             (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FuzzyRules (FuzzyLayer)         (None, 3)            24          Inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Normalization (NormalizedLayer) (None, 3)            0           FuzzyRules[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weights (WeightedLayer)         (None, 3)            15          Inputs[0][0]                     \n",
      "                                                                 Normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RawOutput (OutputLayer)         (None, 1)            0           Weights[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Dense)                 (None, 3)            6           RawOutput[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.get_layer_weights(1)[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (4, 2) not compatible with provided weight shape (4, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5ed77af4b4db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_new\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1055\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                                  \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                                  'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m   1058\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer weight shape (4, 2) not compatible with provided weight shape (4, 3)"
     ]
    }
   ],
   "source": [
    "network.get_layer(1).set_weights([c_new, s_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[6.232648 , 6.3556323],\n",
       "        [2.6747189, 2.799956 ],\n",
       "        [4.842364 , 5.239593 ],\n",
       "        [1.8636686, 1.8425534]], dtype=float32), array([[3.8882833, 4.092967 ],\n",
       "        [3.8793576, 4.101973 ],\n",
       "        [3.9268997, 4.066683 ],\n",
       "        [3.9271975, 4.0689926]], dtype=float32), array([[-0.15375721, -0.05119193],\n",
       "        [ 0.0032294 ,  0.0022638 ],\n",
       "        [-0.1414709 , -0.1687291 ],\n",
       "        [ 0.14846642,  0.17749232],\n",
       "        [ 0.18237953,  0.18902668]], dtype=float32), array([[0.21429645, 1.0758615 , 1.2992578 ]], dtype=float32), array([ 0.1011592 , -0.02520198, -0.06069154], dtype=float32)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_0 = mod2.get_weights()\n",
    "w_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(4, 2)\n",
      "(5, 2)\n",
      "(1, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for w in w_0: print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "FuzzyRules\n",
      "(4, 2)\n",
      "(4, 2)\n",
      "Normalization\n",
      "Weights\n",
      "(5, 2)\n",
      "RawOutput\n",
      "Softmax\n",
      "(1, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for layer in mod2.layers:\n",
    "    print(layer.name)\n",
    "    for w in layer.get_weights():\n",
    "        print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(4, 2)\n",
      "(5, 2)\n",
      "(1, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for w in mod2.get_weights():\n",
    "    print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs\n",
      "FuzzyRules\n",
      "(4, 3)\n",
      "(4, 3)\n",
      "Normalization\n",
      "Weights\n",
      "(5, 3)\n",
      "RawOutput\n",
      "Softmax\n",
      "(1, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "for layer in mod_test.layers:\n",
    "    print(layer.name)\n",
    "    for w in layer.get_weights():\n",
    "        print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sofnn.model.get_weights()\n",
    "c_curr, s_curr, a_curr = w[0], w[1], w[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15375721, -0.05119193],\n",
       "       [ 0.0032294 ,  0.0022638 ],\n",
       "       [-0.1414709 , -0.1687291 ],\n",
       "       [ 0.14846642,  0.17749232],\n",
       "       [ 0.18237953,  0.18902668]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_add = np.ones((a_curr.shape[-2]))\n",
    "a_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_add.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_curr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15375721, -0.05119193,  1.        ],\n",
       "       [ 0.0032294 ,  0.0022638 ,  1.        ],\n",
       "       [-0.14147089, -0.1687291 ,  1.        ],\n",
       "       [ 0.14846642,  0.17749232,  1.        ],\n",
       "       [ 0.18237953,  0.18902668,  1.        ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_new = np.column_stack((a_curr, a_add))\n",
    "a_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'FuzzyNetwork',\n",
       " 'layers': [{'name': 'Inputs',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 4),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'Inputs'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'FuzzyRules',\n",
       "   'class_name': 'FuzzyLayer',\n",
       "   'config': {'name': 'FuzzyRules',\n",
       "    'trainable': True,\n",
       "    'output_dim': 3,\n",
       "    'initializer_centers': None,\n",
       "    'initializer_sigmas': None},\n",
       "   'inbound_nodes': [[['Inputs', 0, 0, {}]]]},\n",
       "  {'name': 'Normalization',\n",
       "   'class_name': 'NormalizedLayer',\n",
       "   'config': {'name': 'Normalization', 'trainable': True, 'output_dim': 3},\n",
       "   'inbound_nodes': [[['FuzzyRules', 0, 0, {}]]]},\n",
       "  {'name': 'Weights',\n",
       "   'class_name': 'WeightedLayer',\n",
       "   'config': {'name': 'Weights', 'trainable': True, 'output_dim': 3},\n",
       "   'inbound_nodes': [[['Inputs', 0, 0, {}], ['Normalization', 0, 0, {}]]]},\n",
       "  {'name': 'RawOutput',\n",
       "   'class_name': 'OutputLayer',\n",
       "   'config': {'name': 'RawOutput', 'trainable': True},\n",
       "   'inbound_nodes': [[['Weights', 0, 0, {}]]]},\n",
       "  {'name': 'Softmax',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'Softmax',\n",
       "    'trainable': True,\n",
       "    'units': 3,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['RawOutput', 0, 0, {}]]]}],\n",
       " 'input_layers': [['Inputs', 0, 0]],\n",
       " 'output_layers': [['Softmax', 0, 0]]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_neurons = 3\n",
    "\n",
    "cust_config = mod2.get_config()\n",
    "for layer in cust_config['layers']:\n",
    "    if 'output_dim' in layer['config']:\n",
    "        layer['config']['output_dim'] = new_neurons\n",
    "cust_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'FuzzyLayer': FuzzyLayer,\n",
    "                  'NormalizedLayer': NormalizedLayer,\n",
    "                  'WeightedLayer': WeightedLayer,\n",
    "                  'OutputLayer': OutputLayer}\n",
    "\n",
    "\n",
    "mod_test = Model.from_config(cust_config, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Inputs (InputLayer)             (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FuzzyRules (FuzzyLayer)         (None, 3)            24          Inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Normalization (NormalizedLayer) (None, 3)            0           FuzzyRules[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weights (WeightedLayer)         (None, 3)            15          Inputs[0][0]                     \n",
      "                                                                 Normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RawOutput (OutputLayer)         (None, 1)            0           Weights[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Dense)                 (None, 3)            6           RawOutput[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01608762,  0.0495098 , -0.00716443],\n",
       "        [-0.03138988, -0.04511898,  0.02483669],\n",
       "        [ 0.00100441,  0.0139542 ,  0.03746018],\n",
       "        [ 0.03787808,  0.00742628,  0.00849212],\n",
       "        [ 0.02752923, -0.04622564, -0.02791619]], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_test.get_layer('Weights').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,s = sofnn.new_neuron_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.02636433, 3.19501448, 1.09113073, 1.16740741])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.11600065, 4.12234783, 3.78088975, 2.28123438])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42198706, 0.36054853, 0.21746439],\n",
       "       [0.26561445, 0.27967227, 0.45471323],\n",
       "       [0.4180984 , 0.3592678 , 0.22263381],\n",
       "       [0.2634889 , 0.27820334, 0.45830783],\n",
       "       [0.23521057, 0.25779092, 0.50699854],\n",
       "       [0.29282996, 0.29766455, 0.40950555],\n",
       "       [0.21743727, 0.24413411, 0.53842866],\n",
       "       [0.4228344 , 0.36082187, 0.21634373],\n",
       "       [0.31141686, 0.30906844, 0.37951472],\n",
       "       [0.20374522, 0.23317428, 0.5630805 ],\n",
       "       [0.20752625, 0.2362393 , 0.5562345 ],\n",
       "       [0.22017133, 0.24627665, 0.533552  ],\n",
       "       [0.25564608, 0.27270404, 0.47164986],\n",
       "       [0.16668762, 0.2015428 , 0.6317696 ],\n",
       "       [0.25087866, 0.2693003 , 0.479821  ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = network.model_predictions()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Widening centers...\n",
      "Centers widened after 0 iterations\n"
     ]
    }
   ],
   "source": [
    "sofnn.widen_centers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test neuron pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create copy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Inputs (InputLayer)             (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FuzzyRules (FuzzyLayer)         (None, 2)            16          Inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Normalization (NormalizedLayer) (None, 2)            0           FuzzyRules[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weights (WeightedLayer)         (None, 2)            10          Inputs[0][0]                     \n",
      "                                                                 Normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RawOutput (OutputLayer)         (None, 1)            0           Weights[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Dense)                 (None, 3)            6           RawOutput[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_model = sofnn.duplicate_model()\n",
    "prune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15689440585337014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_rmse = mean_squared_error(network.y_test, y_pred)\n",
    "E_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.3696566 ,  4.603665  ,  5.1672697 ,  6.9880404 ,  6.922022  ],\n",
       "        [ 2.5602474 ,  3.4443538 ,  3.5287325 ,  2.9069643 ,  2.867683  ],\n",
       "        [ 4.269643  ,  1.3399494 ,  1.2576641 ,  5.8979626 ,  4.9017005 ],\n",
       "        [ 1.5707487 , -0.05153421,  0.15369044,  2.693892  ,  1.6926484 ]],\n",
       "       dtype=float32),\n",
       " array([[3.7421691, 3.745316 , 3.7486923, 3.6966   , 3.7478955],\n",
       "        [3.7193928, 4.199241 , 3.9959254, 3.7569969, 3.73914  ],\n",
       "        [3.7529328, 3.7179635, 3.743473 , 3.6929634, 3.7371545],\n",
       "        [3.7818456, 3.7100377, 3.7327769, 3.6916182, 3.6920516]],\n",
       "       dtype=float32),\n",
       " array([[ 1.05593232e-02, -2.27281332e-01, -2.09979936e-01,\n",
       "          7.50357881e-02,  7.80951381e-02],\n",
       "        [ 6.46460354e-02, -2.60521203e-01, -1.65035546e-01,\n",
       "          1.42984614e-01,  5.43518737e-02],\n",
       "        [-1.82116944e-02, -2.64333963e-01, -1.87058493e-01,\n",
       "          1.24080576e-01,  2.01590854e-04],\n",
       "        [ 1.56993359e-01,  5.01807891e-02, -1.33926068e-02,\n",
       "          1.63400292e-01,  1.61543831e-01],\n",
       "        [ 1.95234418e-01,  1.24412201e-01,  9.77834612e-02,\n",
       "          1.81245059e-01,  1.64195359e-01]], dtype=float32),\n",
       " array([[-0.95694876, -0.49273744,  0.2957787 ]], dtype=float32),\n",
       " array([ 0.11871638, -0.04034704, -0.08038242], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_weights = network.model.get_weights()\n",
    "act_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: FuzzyLayer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-99d447167e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msofnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1008\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 138\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: FuzzyLayer"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_E = []\n",
    "for neur in range(network.neurons):\n",
    "    # reset prune model weights to actual weights\n",
    "    prune_model.set_weights(act_weights)\n",
    "\n",
    "    # get current prune weights\n",
    "    c, s, a = prune_model.get_weights()\n",
    "    # zero our i neuron column in weight vector\n",
    "    a[:, neur] = 0\n",
    "    prune_model.set_weights([c, s, a])\n",
    "\n",
    "    # predict values with new zeroed out weights\n",
    "    neur_pred = prune_model.predict(fuzzy_net.X_test)\n",
    "    y_pred_neur = np.squeeze(np.where(neur_pred >= self._eval_thresh, 1, 0), axis=-1)\n",
    "    neur_rmae = mean_absolute_error(fuzzy_net.y_test, y_pred_neur)\n",
    "\n",
    "    # append difference in rmse and new prediction rmse\n",
    "    delta_E.append(neur_rmae - E_rmae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding neuron...\n",
      "Building Fuzzy Network with 6 neurons...\n",
      "...Model successfully built!\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7b1cc4da4ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msofnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/sofenn/sofenn/SelfOrganizer.py\u001b[0m in \u001b[0;36madd_neuron\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# retrain model since new neuron added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;31m# TODO: add retrain model vs train method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# TODO: validate logic and update references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sofenn/sofenn/SelfOrganizer.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# pass parameters to network method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# TODO: add function to recompile model using current settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sofenn/sofenn/FuzzyNetwork.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# fit model to dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    682\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "sofnn.add_neuron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.6707 - binary_accuracy: 0.6667\n",
      "Epoch 2/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6608 - binary_accuracy: 0.6667\n",
      "Epoch 3/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6566 - binary_accuracy: 0.6667\n",
      "Epoch 4/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6520 - binary_accuracy: 0.6667\n",
      "Epoch 5/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6440 - binary_accuracy: 0.6667\n",
      "Epoch 6/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6330 - binary_accuracy: 0.6667\n",
      "Epoch 7/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6170 - binary_accuracy: 0.6667\n",
      "Epoch 8/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5963 - binary_accuracy: 0.6691\n",
      "Epoch 9/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5758 - binary_accuracy: 0.7086\n",
      "Epoch 10/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5492 - binary_accuracy: 0.7679\n",
      "Epoch 11/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5211 - binary_accuracy: 0.7679\n",
      "Epoch 12/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4973 - binary_accuracy: 0.7679\n",
      "Epoch 13/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4729 - binary_accuracy: 0.7630\n",
      "Epoch 14/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4538 - binary_accuracy: 0.7358\n",
      "Epoch 15/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4327 - binary_accuracy: 0.7432\n",
      "Epoch 16/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4156 - binary_accuracy: 0.7407\n",
      "Epoch 17/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4002 - binary_accuracy: 0.7506\n",
      "Epoch 18/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3869 - binary_accuracy: 0.7630\n",
      "Epoch 19/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3751 - binary_accuracy: 0.7728\n",
      "Epoch 20/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3656 - binary_accuracy: 0.7728\n",
      "Epoch 21/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3584 - binary_accuracy: 0.7951\n",
      "Epoch 22/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3504 - binary_accuracy: 0.8741\n",
      "Epoch 23/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3433 - binary_accuracy: 0.8420\n",
      "Epoch 24/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3388 - binary_accuracy: 0.8247\n",
      "Epoch 25/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3338 - binary_accuracy: 0.8049\n",
      "Epoch 26/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3295 - binary_accuracy: 0.8049\n",
      "Epoch 27/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3259 - binary_accuracy: 0.8000\n",
      "Epoch 28/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3207 - binary_accuracy: 0.8000\n",
      "Epoch 29/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3182 - binary_accuracy: 0.8025\n",
      "Epoch 30/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3150 - binary_accuracy: 0.8000\n",
      "Epoch 31/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3096 - binary_accuracy: 0.8099\n",
      "Epoch 32/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3035 - binary_accuracy: 0.8148\n",
      "Epoch 33/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2987 - binary_accuracy: 0.8123\n",
      "Epoch 34/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2955 - binary_accuracy: 0.8148\n",
      "Epoch 35/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2898 - binary_accuracy: 0.8173\n",
      "Epoch 36/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2835 - binary_accuracy: 0.8272\n",
      "Epoch 37/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2759 - binary_accuracy: 0.8321\n",
      "Epoch 38/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2728 - binary_accuracy: 0.8296\n",
      "Epoch 39/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2671 - binary_accuracy: 0.8346\n",
      "Epoch 40/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2586 - binary_accuracy: 0.8395\n",
      "Epoch 41/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2562 - binary_accuracy: 0.8395\n",
      "Epoch 42/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2490 - binary_accuracy: 0.8420\n",
      "Epoch 43/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2441 - binary_accuracy: 0.8519\n",
      "Epoch 44/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2373 - binary_accuracy: 0.8469\n",
      "Epoch 45/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2320 - binary_accuracy: 0.8568\n",
      "Epoch 46/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2279 - binary_accuracy: 0.8469\n",
      "Epoch 47/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2208 - binary_accuracy: 0.8568\n",
      "Epoch 48/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2136 - binary_accuracy: 0.8790\n",
      "Epoch 49/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2106 - binary_accuracy: 0.9062\n",
      "Epoch 50/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2022 - binary_accuracy: 0.9185\n",
      "Epoch 51/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1967 - binary_accuracy: 0.9210\n",
      "Epoch 52/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.9333\n",
      "Epoch 53/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1884 - binary_accuracy: 0.9358\n",
      "Epoch 54/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1805 - binary_accuracy: 0.9432\n",
      "Epoch 55/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1767 - binary_accuracy: 0.9531\n",
      "Epoch 56/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1702 - binary_accuracy: 0.9605\n",
      "Epoch 57/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1636 - binary_accuracy: 0.9654\n",
      "Epoch 58/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1614 - binary_accuracy: 0.9654\n",
      "Epoch 59/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1558 - binary_accuracy: 0.9728\n",
      "Epoch 60/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1513 - binary_accuracy: 0.9753\n",
      "Epoch 61/250\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1483 - binary_accuracy: 0.9704\n",
      "Epoch 62/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1425 - binary_accuracy: 0.9778\n",
      "Epoch 63/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1387 - binary_accuracy: 0.9753\n",
      "Epoch 64/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1344 - binary_accuracy: 0.9728\n",
      "Epoch 65/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1319 - binary_accuracy: 0.9753\n",
      "Epoch 66/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1264 - binary_accuracy: 0.9852\n",
      "Epoch 67/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1221 - binary_accuracy: 0.9802\n",
      "Epoch 68/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9802\n",
      "Epoch 69/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1151 - binary_accuracy: 0.9852\n",
      "Epoch 70/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1125 - binary_accuracy: 0.9852\n",
      "Epoch 71/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1096 - binary_accuracy: 0.9852\n",
      "Epoch 72/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1052 - binary_accuracy: 0.9802\n",
      "Epoch 73/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1034 - binary_accuracy: 0.9802\n",
      "Epoch 74/250\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1000 - binary_accuracy: 0.9802\n",
      "Epoch 75/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0979 - binary_accuracy: 0.9802\n",
      "Epoch 76/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0959 - binary_accuracy: 0.9802\n",
      "Epoch 77/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0915 - binary_accuracy: 0.9852\n",
      "Epoch 78/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0901 - binary_accuracy: 0.9802\n",
      "Epoch 79/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0901 - binary_accuracy: 0.9852\n",
      "Epoch 80/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0864 - binary_accuracy: 0.9827\n",
      "Epoch 81/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0839 - binary_accuracy: 0.9852\n",
      "Epoch 82/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0818 - binary_accuracy: 0.9827\n",
      "Epoch 83/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0793 - binary_accuracy: 0.9852\n",
      "Epoch 84/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0774 - binary_accuracy: 0.9852\n",
      "Epoch 85/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0763 - binary_accuracy: 0.9852\n",
      "Epoch 86/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0751 - binary_accuracy: 0.9852\n",
      "Epoch 87/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0733 - binary_accuracy: 0.9802\n",
      "Epoch 88/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9852\n",
      "Epoch 89/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0724 - binary_accuracy: 0.9802\n",
      "Epoch 90/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0727 - binary_accuracy: 0.9852\n",
      "Epoch 91/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0682 - binary_accuracy: 0.9852\n",
      "Epoch 92/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0665 - binary_accuracy: 0.9852\n",
      "Epoch 93/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 0.9852\n",
      "Epoch 94/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0652 - binary_accuracy: 0.9852\n",
      "Epoch 95/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9852\n",
      "Epoch 96/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0623 - binary_accuracy: 0.9852\n",
      "Epoch 97/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9852\n",
      "Epoch 98/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9852\n",
      "Epoch 99/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9852\n",
      "Epoch 100/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9852\n",
      "Epoch 101/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9852\n",
      "Epoch 102/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9852\n",
      "Epoch 103/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9802\n",
      "Epoch 104/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0556 - binary_accuracy: 0.9852\n",
      "Epoch 105/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9852\n",
      "Epoch 106/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0545 - binary_accuracy: 0.9802\n",
      "Epoch 107/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9852\n",
      "Epoch 108/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0496 - binary_accuracy: 0.9852\n",
      "Epoch 109/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9852\n",
      "Epoch 110/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0514 - binary_accuracy: 0.9802\n",
      "Epoch 111/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0506 - binary_accuracy: 0.9852\n",
      "Epoch 112/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9852\n",
      "Epoch 113/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0497 - binary_accuracy: 0.9852\n",
      "Epoch 114/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0507 - binary_accuracy: 0.9802\n",
      "Epoch 115/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0499 - binary_accuracy: 0.9852\n",
      "Epoch 116/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0486 - binary_accuracy: 0.9852\n",
      "Epoch 117/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0478 - binary_accuracy: 0.9852\n",
      "Epoch 118/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0475 - binary_accuracy: 0.9852\n",
      "Epoch 119/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0464 - binary_accuracy: 0.9852\n",
      "Epoch 120/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0472 - binary_accuracy: 0.9852\n",
      "Epoch 121/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0473 - binary_accuracy: 0.9852\n",
      "Epoch 122/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0456 - binary_accuracy: 0.9852\n",
      "Epoch 123/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0454 - binary_accuracy: 0.9901\n",
      "Epoch 124/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0446 - binary_accuracy: 0.9852\n",
      "Epoch 125/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0445 - binary_accuracy: 0.9901\n",
      "Epoch 126/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0438 - binary_accuracy: 0.9852\n",
      "Epoch 127/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0442 - binary_accuracy: 0.9852\n",
      "Epoch 128/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0441 - binary_accuracy: 0.9852\n",
      "Epoch 129/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0432 - binary_accuracy: 0.9852\n",
      "Epoch 130/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0452 - binary_accuracy: 0.9802\n",
      "Epoch 131/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0420 - binary_accuracy: 0.9802\n",
      "Epoch 132/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0415 - binary_accuracy: 0.9852\n",
      "Epoch 133/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0416 - binary_accuracy: 0.9852\n",
      "Epoch 134/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0413 - binary_accuracy: 0.9901\n",
      "Epoch 135/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0406 - binary_accuracy: 0.9852\n",
      "Epoch 136/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0423 - binary_accuracy: 0.9802\n",
      "Epoch 137/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0414 - binary_accuracy: 0.9852\n",
      "Epoch 138/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0408 - binary_accuracy: 0.9852\n",
      "Epoch 139/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0405 - binary_accuracy: 0.9852\n",
      "Epoch 140/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0379 - binary_accuracy: 0.9852\n",
      "Epoch 141/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0416 - binary_accuracy: 0.9852\n",
      "Epoch 142/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0403 - binary_accuracy: 0.9852\n",
      "Epoch 143/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0405 - binary_accuracy: 0.9802\n",
      "Epoch 144/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0394 - binary_accuracy: 0.9802\n",
      "Epoch 145/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0391 - binary_accuracy: 0.9802\n",
      "Epoch 146/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0377 - binary_accuracy: 0.9852\n",
      "Epoch 147/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0385 - binary_accuracy: 0.9802\n",
      "Epoch 148/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0382 - binary_accuracy: 0.9852\n",
      "Epoch 149/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0422 - binary_accuracy: 0.9852\n",
      "Epoch 150/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0377 - binary_accuracy: 0.9852\n",
      "Epoch 151/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0384 - binary_accuracy: 0.9802\n",
      "Epoch 152/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0380 - binary_accuracy: 0.9852\n",
      "Epoch 153/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0370 - binary_accuracy: 0.9852\n",
      "Epoch 154/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0376 - binary_accuracy: 0.9852\n",
      "Epoch 155/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0372 - binary_accuracy: 0.9852\n",
      "Epoch 156/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0372 - binary_accuracy: 0.9852\n",
      "Epoch 157/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0374 - binary_accuracy: 0.9852\n",
      "Epoch 158/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0373 - binary_accuracy: 0.9852\n",
      "Epoch 159/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0359 - binary_accuracy: 0.9852\n",
      "Epoch 160/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0365 - binary_accuracy: 0.9852\n",
      "Epoch 161/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0359 - binary_accuracy: 0.9852\n",
      "Epoch 162/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0361 - binary_accuracy: 0.9852\n",
      "Epoch 163/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0356 - binary_accuracy: 0.9852\n",
      "Epoch 164/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0353 - binary_accuracy: 0.9852\n",
      "Epoch 165/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0347 - binary_accuracy: 0.9852\n",
      "Epoch 166/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0355 - binary_accuracy: 0.9852\n",
      "Epoch 167/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0349 - binary_accuracy: 0.9901\n",
      "Epoch 168/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0350 - binary_accuracy: 0.9852\n",
      "Epoch 169/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0346 - binary_accuracy: 0.9901\n",
      "Epoch 170/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0354 - binary_accuracy: 0.9852\n",
      "Epoch 171/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0346 - binary_accuracy: 0.9852\n",
      "Epoch 172/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0371 - binary_accuracy: 0.9802\n",
      "Epoch 173/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0339 - binary_accuracy: 0.9852\n",
      "Epoch 174/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0335 - binary_accuracy: 0.9852\n",
      "Epoch 175/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0342 - binary_accuracy: 0.9901\n",
      "Epoch 176/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0345 - binary_accuracy: 0.9852\n",
      "Epoch 177/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0348 - binary_accuracy: 0.9852\n",
      "Epoch 178/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0340 - binary_accuracy: 0.9852\n",
      "Epoch 179/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0326 - binary_accuracy: 0.9852\n",
      "Epoch 180/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0350 - binary_accuracy: 0.9852\n",
      "Epoch 181/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0360 - binary_accuracy: 0.9852\n",
      "Epoch 182/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0337 - binary_accuracy: 0.9901\n",
      "Epoch 183/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0341 - binary_accuracy: 0.9802\n",
      "Epoch 184/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0343 - binary_accuracy: 0.9901\n",
      "Epoch 185/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0349 - binary_accuracy: 0.9852\n",
      "Epoch 186/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0320 - binary_accuracy: 0.9901\n",
      "Epoch 187/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0327 - binary_accuracy: 0.9852\n",
      "Epoch 188/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0351 - binary_accuracy: 0.9852\n",
      "Epoch 189/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0332 - binary_accuracy: 0.9901\n",
      "Epoch 190/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0323 - binary_accuracy: 0.9901\n",
      "Epoch 191/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0327 - binary_accuracy: 0.9901\n",
      "Epoch 192/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9852\n",
      "Epoch 193/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0343 - binary_accuracy: 0.9852\n",
      "Epoch 194/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0313 - binary_accuracy: 0.9901\n",
      "Epoch 195/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0316 - binary_accuracy: 0.9901\n",
      "Epoch 196/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0340 - binary_accuracy: 0.9901\n",
      "Epoch 197/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0323 - binary_accuracy: 0.9901\n",
      "Epoch 198/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0319 - binary_accuracy: 0.9852\n",
      "Epoch 199/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9852\n",
      "Epoch 200/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0311 - binary_accuracy: 0.9901\n",
      "Epoch 201/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0321 - binary_accuracy: 0.9901\n",
      "Epoch 202/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0313 - binary_accuracy: 0.9852\n",
      "Epoch 203/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0314 - binary_accuracy: 0.9852\n",
      "Epoch 204/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0312 - binary_accuracy: 0.9852\n",
      "Epoch 205/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9802\n",
      "Epoch 206/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0309 - binary_accuracy: 0.9901\n",
      "Epoch 207/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0310 - binary_accuracy: 0.9852\n",
      "Epoch 208/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0322 - binary_accuracy: 0.9852\n",
      "Epoch 209/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0309 - binary_accuracy: 0.9901\n",
      "Epoch 210/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0315 - binary_accuracy: 0.9852\n",
      "Epoch 211/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0312 - binary_accuracy: 0.9852\n",
      "Epoch 212/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0312 - binary_accuracy: 0.9901\n",
      "Epoch 213/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0304 - binary_accuracy: 0.9901\n",
      "Epoch 214/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0323 - binary_accuracy: 0.9901\n",
      "Epoch 215/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0308 - binary_accuracy: 0.9901\n",
      "Epoch 216/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0303 - binary_accuracy: 0.9852\n",
      "Epoch 217/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0298 - binary_accuracy: 0.9901\n",
      "Epoch 218/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0303 - binary_accuracy: 0.9901\n",
      "Epoch 219/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0309 - binary_accuracy: 0.9901\n",
      "Epoch 220/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0325 - binary_accuracy: 0.9852\n",
      "Epoch 221/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0298 - binary_accuracy: 0.9901\n",
      "Epoch 222/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0302 - binary_accuracy: 0.9901\n",
      "Epoch 223/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0310 - binary_accuracy: 0.9901\n",
      "Epoch 224/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0300 - binary_accuracy: 0.9901\n",
      "Epoch 225/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0311 - binary_accuracy: 0.9901\n",
      "Epoch 226/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0329 - binary_accuracy: 0.9901\n",
      "Epoch 227/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0316 - binary_accuracy: 0.9901\n",
      "Epoch 228/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9852\n",
      "Epoch 229/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0307 - binary_accuracy: 0.9852\n",
      "Epoch 230/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0289 - binary_accuracy: 0.9901\n",
      "Epoch 231/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0297 - binary_accuracy: 0.9901\n",
      "Epoch 232/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0299 - binary_accuracy: 0.9852\n",
      "Epoch 233/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0300 - binary_accuracy: 0.9852\n",
      "Epoch 234/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0293 - binary_accuracy: 0.9901\n",
      "Epoch 235/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0299 - binary_accuracy: 0.9901\n",
      "Epoch 236/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0292 - binary_accuracy: 0.9901\n",
      "Epoch 237/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0299 - binary_accuracy: 0.9901\n",
      "Epoch 238/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0294 - binary_accuracy: 0.9901\n",
      "Epoch 239/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0286 - binary_accuracy: 0.9901\n",
      "Epoch 240/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0310 - binary_accuracy: 0.9901\n",
      "Epoch 241/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0296 - binary_accuracy: 0.9901\n",
      "Epoch 242/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0301 - binary_accuracy: 0.9852\n",
      "Epoch 243/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0285 - binary_accuracy: 0.9901\n",
      "Epoch 244/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0285 - binary_accuracy: 0.9901\n",
      "Epoch 245/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0289 - binary_accuracy: 0.9901\n",
      "Epoch 246/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0282 - binary_accuracy: 0.9901\n",
      "Epoch 247/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0285 - binary_accuracy: 0.9901\n",
      "Epoch 248/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0281 - binary_accuracy: 0.9901\n",
      "Epoch 249/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0292 - binary_accuracy: 0.9852\n",
      "Epoch 250/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0292 - binary_accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a32d24f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss = 'mean_squared_error'\n",
    "loss = fuzz.loss_function\n",
    "optimizer = 'adam'\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "model = fuzz.model\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics)\n",
    "\n",
    "model.fit(np.array(X_train),\n",
    "          np.array(y_train),\n",
    "          epochs=250,\n",
    "          verbose=1,\n",
    "          batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.1073303,  5.8863463,  3.8469965],\n",
       "        [ 2.4748902,  4.0579185,  1.1891739],\n",
       "        [ 6.9911284,  1.0462298,  3.7106006],\n",
       "        [ 3.7091155, -0.3453039,  2.5200057]], dtype=float32),\n",
       " array([[3.9457917, 5.1618943, 2.0746884],\n",
       "        [3.2234733, 3.435901 , 2.1246395],\n",
       "        [2.0414689, 3.5269158, 2.0570922],\n",
       "        [1.4811075, 2.9864326, 1.6324853]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz._get_layer_weights('FuzzyRules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.6, 1.4, 0.2],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [4.8, 3.1, 1.6, 0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = y_test == y_pred.round()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.sum() / acc.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 9ms/step\n",
      "Model Loss: 0.43104896\n",
      "Binary Accuracy: 95.6%\n"
     ]
    }
   ],
   "source": [
    "pred_loss, pred_bin_acc = model.evaluate(X_test, y_test)\n",
    "print('Model Loss: {:0.8f}'.format(pred_loss))\n",
    "print('Binary Accuracy: {:2.1f}%'.format(100*pred_bin_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'binary_accuracy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = fuzz._get_layer_weights('FuzzyRules')\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.title('Iris')\n",
    "plt.ylabel('x[0]')\n",
    "plt.xlabel('x[1]')\n",
    "plt.scatter([a[0] for a in X_train], [a[1] for a in X_train], c=(0,0,0), alpha=0.5,s=1)\n",
    "for i in range(0,fuzz.neurons):\n",
    "    ellipse = Ellipse((w[0][0][i], w[0][1][i]), w[1][0][i],w[1][1][i], color='r', fill=False)\n",
    "    ax = plt.gca()\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "plt.scatter(w[0][0], w[0][1], c=(1,0,0), alpha=0.8,s=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
