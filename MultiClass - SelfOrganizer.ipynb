{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Iris Dataset - SOFENN Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate multi-class classification with SOFENN on classic Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, load_model, clone_model\n",
    "\n",
    "from sofenn import SelfOrganizer\n",
    "from sofenn.FuzzyNetwork import FuzzyNetwork\n",
    "from sofenn.layers import FuzzyLayer, NormalizedLayer, WeightedLayer, OutputLayer\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and prep Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in iris dataset\n",
    "iris = datasets.load_iris()\n",
    "# create one-hot encoded vector for each class\n",
    "Y = []\n",
    "for y in iris.target:\n",
    "    tmp = np.zeros(3)\n",
    "    tmp[y] = 1\n",
    "    Y.append(tmp)\n",
    "Y = np.array(Y)\n",
    "    \n",
    "# split to train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Self Organizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofnn = SelfOrganizer(\n",
    "             ksig=1.12, max_widens=250,          # adding neuron or widening centers\n",
    "             prune_tol=0.85, k_mae=0.1,          # pruning parameters\n",
    "             debug=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Fuzzy Network with 5 neurons...\n",
      "WARNING:tensorflow:From /miniconda3/envs/sofenn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "...Model successfully built!\n"
     ]
    }
   ],
   "source": [
    "start_neurons = 5\n",
    "\n",
    "sofnn.build_network(\n",
    "                 X_train, X_test, y_train, y_test,        # data attributes\n",
    "                 neurons=start_neurons, max_neurons=100,  # neuron initialization parameters\n",
    "                 ifpart_thresh=0.1354,                    # ifpart and error thresholds\n",
    "                 prob_type='classification'               # type of problem (classification/regression)\n",
    ")\n",
    "\n",
    "network = sofnn.network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Inputs (InputLayer)             (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FuzzyRules (FuzzyLayer)         (None, 5)            40          Inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Normalization (NormalizedLayer) (None, 5)            0           FuzzyRules[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weights (WeightedLayer)         (None, 5)            25          Inputs[0][0]                     \n",
      "                                                                 Normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RawOutput (OutputLayer)         (None, 1)            0           Weights[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Dense)                 (None, 3)            6           RawOutput[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 71\n",
      "Trainable params: 71\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "loss = sofnn.network.loss_function\n",
    "optimizer = 'adam'\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "sofnn.compile_model(init_c=True, random=True, init_s=True, s_0=4.0,\n",
    "                    loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "WARNING:tensorflow:From /miniconda3/envs/sofenn/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/45\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 10.0951 - binary_accuracy: 0.6667\n",
      "Epoch 2/45\n",
      "135/135 [==============================] - 0s 158us/step - loss: 9.9237 - binary_accuracy: 0.6667\n",
      "Epoch 3/45\n",
      "135/135 [==============================] - 0s 226us/step - loss: 9.7942 - binary_accuracy: 0.6667\n",
      "Epoch 4/45\n",
      "135/135 [==============================] - 0s 171us/step - loss: 9.6762 - binary_accuracy: 0.6667\n",
      "Epoch 5/45\n",
      "135/135 [==============================] - 0s 165us/step - loss: 9.5179 - binary_accuracy: 0.6667\n",
      "Epoch 6/45\n",
      "135/135 [==============================] - 0s 116us/step - loss: 9.4245 - binary_accuracy: 0.6667\n",
      "Epoch 7/45\n",
      "135/135 [==============================] - 0s 127us/step - loss: 9.3056 - binary_accuracy: 0.6667\n",
      "Epoch 8/45\n",
      "135/135 [==============================] - 0s 164us/step - loss: 9.2553 - binary_accuracy: 0.6691\n",
      "Epoch 9/45\n",
      "135/135 [==============================] - 0s 170us/step - loss: 9.0611 - binary_accuracy: 0.6765\n",
      "Epoch 10/45\n",
      "135/135 [==============================] - 0s 166us/step - loss: 8.9854 - binary_accuracy: 0.6864\n",
      "Epoch 11/45\n",
      "135/135 [==============================] - 0s 138us/step - loss: 8.9000 - binary_accuracy: 0.6938\n",
      "Epoch 12/45\n",
      "135/135 [==============================] - 0s 157us/step - loss: 8.7626 - binary_accuracy: 0.7037\n",
      "Epoch 13/45\n",
      "135/135 [==============================] - 0s 162us/step - loss: 8.6521 - binary_accuracy: 0.7086\n",
      "Epoch 14/45\n",
      "135/135 [==============================] - 0s 159us/step - loss: 8.4945 - binary_accuracy: 0.7210\n",
      "Epoch 15/45\n",
      "135/135 [==============================] - 0s 148us/step - loss: 8.4336 - binary_accuracy: 0.7259\n",
      "Epoch 16/45\n",
      "135/135 [==============================] - 0s 176us/step - loss: 8.3798 - binary_accuracy: 0.7333\n",
      "Epoch 17/45\n",
      "135/135 [==============================] - 0s 156us/step - loss: 8.2015 - binary_accuracy: 0.7407\n",
      "Epoch 18/45\n",
      "135/135 [==============================] - 0s 183us/step - loss: 8.1287 - binary_accuracy: 0.7407\n",
      "Epoch 19/45\n",
      "135/135 [==============================] - 0s 147us/step - loss: 8.0489 - binary_accuracy: 0.7432\n",
      "Epoch 20/45\n",
      "135/135 [==============================] - 0s 165us/step - loss: 7.9266 - binary_accuracy: 0.7457\n",
      "Epoch 21/45\n",
      "135/135 [==============================] - 0s 165us/step - loss: 7.8243 - binary_accuracy: 0.7457\n",
      "Epoch 22/45\n",
      "135/135 [==============================] - 0s 177us/step - loss: 7.7031 - binary_accuracy: 0.7457\n",
      "Epoch 23/45\n",
      "135/135 [==============================] - 0s 159us/step - loss: 7.6743 - binary_accuracy: 0.7556\n",
      "Epoch 24/45\n",
      "135/135 [==============================] - 0s 141us/step - loss: 7.4524 - binary_accuracy: 0.7605\n",
      "Epoch 25/45\n",
      "135/135 [==============================] - 0s 161us/step - loss: 7.4288 - binary_accuracy: 0.7728\n",
      "Epoch 26/45\n",
      "135/135 [==============================] - 0s 160us/step - loss: 7.3635 - binary_accuracy: 0.8049\n",
      "Epoch 27/45\n",
      "135/135 [==============================] - 0s 161us/step - loss: 7.2651 - binary_accuracy: 0.8370\n",
      "Epoch 28/45\n",
      "135/135 [==============================] - 0s 141us/step - loss: 7.1535 - binary_accuracy: 0.8568\n",
      "Epoch 29/45\n",
      "135/135 [==============================] - 0s 142us/step - loss: 7.0816 - binary_accuracy: 0.8617\n",
      "Epoch 30/45\n",
      "135/135 [==============================] - 0s 143us/step - loss: 6.9322 - binary_accuracy: 0.8642\n",
      "Epoch 31/45\n",
      "135/135 [==============================] - 0s 133us/step - loss: 6.9014 - binary_accuracy: 0.8667\n",
      "Epoch 32/45\n",
      "135/135 [==============================] - 0s 161us/step - loss: 6.8557 - binary_accuracy: 0.8691\n",
      "Epoch 33/45\n",
      "135/135 [==============================] - 0s 139us/step - loss: 6.5313 - binary_accuracy: 0.8691\n",
      "Epoch 34/45\n",
      "135/135 [==============================] - 0s 128us/step - loss: 6.5370 - binary_accuracy: 0.8716\n",
      "Epoch 35/45\n",
      "135/135 [==============================] - 0s 150us/step - loss: 6.5236 - binary_accuracy: 0.8741\n",
      "Epoch 36/45\n",
      "135/135 [==============================] - 0s 150us/step - loss: 6.4217 - binary_accuracy: 0.8741\n",
      "Epoch 37/45\n",
      "135/135 [==============================] - 0s 141us/step - loss: 6.1937 - binary_accuracy: 0.8741\n",
      "Epoch 38/45\n",
      "135/135 [==============================] - 0s 156us/step - loss: 6.2343 - binary_accuracy: 0.8716\n",
      "Epoch 39/45\n",
      "135/135 [==============================] - 0s 134us/step - loss: 6.2335 - binary_accuracy: 0.8716\n",
      "Epoch 40/45\n",
      "135/135 [==============================] - 0s 170us/step - loss: 6.2348 - binary_accuracy: 0.8716\n",
      "Epoch 41/45\n",
      "135/135 [==============================] - 0s 141us/step - loss: 6.0696 - binary_accuracy: 0.8691\n",
      "Epoch 42/45\n",
      "135/135 [==============================] - 0s 150us/step - loss: 5.9885 - binary_accuracy: 0.8691\n",
      "Epoch 43/45\n",
      "135/135 [==============================] - 0s 156us/step - loss: 5.9594 - binary_accuracy: 0.8716\n",
      "Epoch 44/45\n",
      "135/135 [==============================] - 0s 172us/step - loss: 5.8616 - binary_accuracy: 0.8716\n",
      "Epoch 45/45\n",
      "135/135 [==============================] - 0s 135us/step - loss: 5.8316 - binary_accuracy: 0.8716\n"
     ]
    }
   ],
   "source": [
    "sofnn.train_model(epochs=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,s = sofnn.new_neuron_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.17460155, 2.63537169, 4.70471907, 1.20740741])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.74021173, 3.73521066, 3.74612689, 2.56277739])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70458376, 0.24958563, 0.04583054],\n",
       "       [0.3205753 , 0.32485333, 0.35457137],\n",
       "       [0.4280763 , 0.33535153, 0.23657215],\n",
       "       [0.2631178 , 0.3079046 , 0.42897755],\n",
       "       [0.13931516, 0.2371169 , 0.623568  ],\n",
       "       [0.03515735, 0.11200634, 0.8528363 ],\n",
       "       [0.6905203 , 0.25775394, 0.05172572],\n",
       "       [0.67147803, 0.26817077, 0.06035115],\n",
       "       [0.66590637, 0.27107814, 0.06301539],\n",
       "       [0.0941669 , 0.1946038 , 0.71122926],\n",
       "       [0.65422624, 0.2769661 , 0.06880766],\n",
       "       [0.6658402 , 0.27111235, 0.06304745],\n",
       "       [0.15690224, 0.2507127 , 0.59238505],\n",
       "       [0.1704897 , 0.26028073, 0.56922954],\n",
       "       [0.16169722, 0.254178  , 0.58412474]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = network.model_predictions()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Widening centers...\n",
      "Centers widened after 0 iterations\n"
     ]
    }
   ],
   "source": [
    "sofnn.widen_centers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test neuron pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create copy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Inputs (InputLayer)             (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FuzzyRules (FuzzyLayer)         (None, 5)            40          Inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Normalization (NormalizedLayer) (None, 5)            0           FuzzyRules[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Weights (WeightedLayer)         (None, 5)            25          Inputs[0][0]                     \n",
      "                                                                 Normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RawOutput (OutputLayer)         (None, 1)            0           Weights[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Dense)                 (None, 3)            6           RawOutput[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 71\n",
      "Trainable params: 71\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_model = clone_model(network.model)\n",
    "prune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15689440585337014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_rmse = mean_squared_error(network.y_test, y_pred)\n",
    "E_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.3696566 ,  4.603665  ,  5.1672697 ,  6.9880404 ,  6.922022  ],\n",
       "        [ 2.5602474 ,  3.4443538 ,  3.5287325 ,  2.9069643 ,  2.867683  ],\n",
       "        [ 4.269643  ,  1.3399494 ,  1.2576641 ,  5.8979626 ,  4.9017005 ],\n",
       "        [ 1.5707487 , -0.05153421,  0.15369044,  2.693892  ,  1.6926484 ]],\n",
       "       dtype=float32),\n",
       " array([[3.7421691, 3.745316 , 3.7486923, 3.6966   , 3.7478955],\n",
       "        [3.7193928, 4.199241 , 3.9959254, 3.7569969, 3.73914  ],\n",
       "        [3.7529328, 3.7179635, 3.743473 , 3.6929634, 3.7371545],\n",
       "        [3.7818456, 3.7100377, 3.7327769, 3.6916182, 3.6920516]],\n",
       "       dtype=float32),\n",
       " array([[ 1.05593232e-02, -2.27281332e-01, -2.09979936e-01,\n",
       "          7.50357881e-02,  7.80951381e-02],\n",
       "        [ 6.46460354e-02, -2.60521203e-01, -1.65035546e-01,\n",
       "          1.42984614e-01,  5.43518737e-02],\n",
       "        [-1.82116944e-02, -2.64333963e-01, -1.87058493e-01,\n",
       "          1.24080576e-01,  2.01590854e-04],\n",
       "        [ 1.56993359e-01,  5.01807891e-02, -1.33926068e-02,\n",
       "          1.63400292e-01,  1.61543831e-01],\n",
       "        [ 1.95234418e-01,  1.24412201e-01,  9.77834612e-02,\n",
       "          1.81245059e-01,  1.64195359e-01]], dtype=float32),\n",
       " array([[-0.95694876, -0.49273744,  0.2957787 ]], dtype=float32),\n",
       " array([ 0.11871638, -0.04034704, -0.08038242], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_weights = network.model.get_weights()\n",
    "act_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: FuzzyLayer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-99d447167e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msofnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1008\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 138\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: FuzzyLayer"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_E = []\n",
    "for neur in range(network.neurons):\n",
    "    # reset prune model weights to actual weights\n",
    "    prune_model.set_weights(act_weights)\n",
    "\n",
    "    # get current prune weights\n",
    "    c, s, a = prune_model.get_weights()\n",
    "    # zero our i neuron column in weight vector\n",
    "    a[:, neur] = 0\n",
    "    prune_model.set_weights([c, s, a])\n",
    "\n",
    "    # predict values with new zeroed out weights\n",
    "    neur_pred = prune_model.predict(fuzzy_net.X_test)\n",
    "    y_pred_neur = np.squeeze(np.where(neur_pred >= self._eval_thresh, 1, 0), axis=-1)\n",
    "    neur_rmae = mean_absolute_error(fuzzy_net.y_test, y_pred_neur)\n",
    "\n",
    "    # append difference in rmse and new prediction rmse\n",
    "    delta_E.append(neur_rmae - E_rmae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding neuron...\n",
      "Building Fuzzy Network with 6 neurons...\n",
      "...Model successfully built!\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7b1cc4da4ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msofnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_neuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/sofenn/sofenn/SelfOrganizer.py\u001b[0m in \u001b[0;36madd_neuron\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# retrain model since new neuron added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;31m# TODO: add retrain model vs train method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# TODO: validate logic and update references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sofenn/sofenn/SelfOrganizer.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# pass parameters to network method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# TODO: add function to recompile model using current settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sofenn/sofenn/FuzzyNetwork.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# fit model to dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/sofenn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    682\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "sofnn.add_neuron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "135/135 [==============================] - 1s 7ms/step - loss: 0.6707 - binary_accuracy: 0.6667\n",
      "Epoch 2/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6608 - binary_accuracy: 0.6667\n",
      "Epoch 3/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6566 - binary_accuracy: 0.6667\n",
      "Epoch 4/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6520 - binary_accuracy: 0.6667\n",
      "Epoch 5/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6440 - binary_accuracy: 0.6667\n",
      "Epoch 6/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6330 - binary_accuracy: 0.6667\n",
      "Epoch 7/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6170 - binary_accuracy: 0.6667\n",
      "Epoch 8/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5963 - binary_accuracy: 0.6691\n",
      "Epoch 9/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5758 - binary_accuracy: 0.7086\n",
      "Epoch 10/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5492 - binary_accuracy: 0.7679\n",
      "Epoch 11/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5211 - binary_accuracy: 0.7679\n",
      "Epoch 12/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4973 - binary_accuracy: 0.7679\n",
      "Epoch 13/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4729 - binary_accuracy: 0.7630\n",
      "Epoch 14/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4538 - binary_accuracy: 0.7358\n",
      "Epoch 15/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4327 - binary_accuracy: 0.7432\n",
      "Epoch 16/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4156 - binary_accuracy: 0.7407\n",
      "Epoch 17/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4002 - binary_accuracy: 0.7506\n",
      "Epoch 18/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3869 - binary_accuracy: 0.7630\n",
      "Epoch 19/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3751 - binary_accuracy: 0.7728\n",
      "Epoch 20/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3656 - binary_accuracy: 0.7728\n",
      "Epoch 21/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3584 - binary_accuracy: 0.7951\n",
      "Epoch 22/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3504 - binary_accuracy: 0.8741\n",
      "Epoch 23/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3433 - binary_accuracy: 0.8420\n",
      "Epoch 24/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3388 - binary_accuracy: 0.8247\n",
      "Epoch 25/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3338 - binary_accuracy: 0.8049\n",
      "Epoch 26/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3295 - binary_accuracy: 0.8049\n",
      "Epoch 27/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3259 - binary_accuracy: 0.8000\n",
      "Epoch 28/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3207 - binary_accuracy: 0.8000\n",
      "Epoch 29/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3182 - binary_accuracy: 0.8025\n",
      "Epoch 30/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3150 - binary_accuracy: 0.8000\n",
      "Epoch 31/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3096 - binary_accuracy: 0.8099\n",
      "Epoch 32/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3035 - binary_accuracy: 0.8148\n",
      "Epoch 33/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2987 - binary_accuracy: 0.8123\n",
      "Epoch 34/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2955 - binary_accuracy: 0.8148\n",
      "Epoch 35/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2898 - binary_accuracy: 0.8173\n",
      "Epoch 36/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2835 - binary_accuracy: 0.8272\n",
      "Epoch 37/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2759 - binary_accuracy: 0.8321\n",
      "Epoch 38/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2728 - binary_accuracy: 0.8296\n",
      "Epoch 39/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2671 - binary_accuracy: 0.8346\n",
      "Epoch 40/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2586 - binary_accuracy: 0.8395\n",
      "Epoch 41/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2562 - binary_accuracy: 0.8395\n",
      "Epoch 42/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2490 - binary_accuracy: 0.8420\n",
      "Epoch 43/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2441 - binary_accuracy: 0.8519\n",
      "Epoch 44/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2373 - binary_accuracy: 0.8469\n",
      "Epoch 45/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2320 - binary_accuracy: 0.8568\n",
      "Epoch 46/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2279 - binary_accuracy: 0.8469\n",
      "Epoch 47/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2208 - binary_accuracy: 0.8568\n",
      "Epoch 48/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2136 - binary_accuracy: 0.8790\n",
      "Epoch 49/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2106 - binary_accuracy: 0.9062\n",
      "Epoch 50/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2022 - binary_accuracy: 0.9185\n",
      "Epoch 51/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1967 - binary_accuracy: 0.9210\n",
      "Epoch 52/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1924 - binary_accuracy: 0.9333\n",
      "Epoch 53/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1884 - binary_accuracy: 0.9358\n",
      "Epoch 54/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1805 - binary_accuracy: 0.9432\n",
      "Epoch 55/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1767 - binary_accuracy: 0.9531\n",
      "Epoch 56/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1702 - binary_accuracy: 0.9605\n",
      "Epoch 57/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1636 - binary_accuracy: 0.9654\n",
      "Epoch 58/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1614 - binary_accuracy: 0.9654\n",
      "Epoch 59/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1558 - binary_accuracy: 0.9728\n",
      "Epoch 60/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1513 - binary_accuracy: 0.9753\n",
      "Epoch 61/250\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1483 - binary_accuracy: 0.9704\n",
      "Epoch 62/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1425 - binary_accuracy: 0.9778\n",
      "Epoch 63/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1387 - binary_accuracy: 0.9753\n",
      "Epoch 64/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1344 - binary_accuracy: 0.9728\n",
      "Epoch 65/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1319 - binary_accuracy: 0.9753\n",
      "Epoch 66/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1264 - binary_accuracy: 0.9852\n",
      "Epoch 67/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1221 - binary_accuracy: 0.9802\n",
      "Epoch 68/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9802\n",
      "Epoch 69/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1151 - binary_accuracy: 0.9852\n",
      "Epoch 70/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1125 - binary_accuracy: 0.9852\n",
      "Epoch 71/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1096 - binary_accuracy: 0.9852\n",
      "Epoch 72/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1052 - binary_accuracy: 0.9802\n",
      "Epoch 73/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1034 - binary_accuracy: 0.9802\n",
      "Epoch 74/250\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1000 - binary_accuracy: 0.9802\n",
      "Epoch 75/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0979 - binary_accuracy: 0.9802\n",
      "Epoch 76/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0959 - binary_accuracy: 0.9802\n",
      "Epoch 77/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0915 - binary_accuracy: 0.9852\n",
      "Epoch 78/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0901 - binary_accuracy: 0.9802\n",
      "Epoch 79/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0901 - binary_accuracy: 0.9852\n",
      "Epoch 80/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0864 - binary_accuracy: 0.9827\n",
      "Epoch 81/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0839 - binary_accuracy: 0.9852\n",
      "Epoch 82/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0818 - binary_accuracy: 0.9827\n",
      "Epoch 83/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0793 - binary_accuracy: 0.9852\n",
      "Epoch 84/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0774 - binary_accuracy: 0.9852\n",
      "Epoch 85/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0763 - binary_accuracy: 0.9852\n",
      "Epoch 86/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0751 - binary_accuracy: 0.9852\n",
      "Epoch 87/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0733 - binary_accuracy: 0.9802\n",
      "Epoch 88/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9852\n",
      "Epoch 89/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0724 - binary_accuracy: 0.9802\n",
      "Epoch 90/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0727 - binary_accuracy: 0.9852\n",
      "Epoch 91/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0682 - binary_accuracy: 0.9852\n",
      "Epoch 92/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0665 - binary_accuracy: 0.9852\n",
      "Epoch 93/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 0.9852\n",
      "Epoch 94/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0652 - binary_accuracy: 0.9852\n",
      "Epoch 95/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9852\n",
      "Epoch 96/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0623 - binary_accuracy: 0.9852\n",
      "Epoch 97/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9852\n",
      "Epoch 98/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9852\n",
      "Epoch 99/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9852\n",
      "Epoch 100/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9852\n",
      "Epoch 101/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9852\n",
      "Epoch 102/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9852\n",
      "Epoch 103/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9802\n",
      "Epoch 104/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0556 - binary_accuracy: 0.9852\n",
      "Epoch 105/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9852\n",
      "Epoch 106/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0545 - binary_accuracy: 0.9802\n",
      "Epoch 107/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9852\n",
      "Epoch 108/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0496 - binary_accuracy: 0.9852\n",
      "Epoch 109/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9852\n",
      "Epoch 110/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0514 - binary_accuracy: 0.9802\n",
      "Epoch 111/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0506 - binary_accuracy: 0.9852\n",
      "Epoch 112/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9852\n",
      "Epoch 113/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0497 - binary_accuracy: 0.9852\n",
      "Epoch 114/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0507 - binary_accuracy: 0.9802\n",
      "Epoch 115/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0499 - binary_accuracy: 0.9852\n",
      "Epoch 116/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0486 - binary_accuracy: 0.9852\n",
      "Epoch 117/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0478 - binary_accuracy: 0.9852\n",
      "Epoch 118/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0475 - binary_accuracy: 0.9852\n",
      "Epoch 119/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0464 - binary_accuracy: 0.9852\n",
      "Epoch 120/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0472 - binary_accuracy: 0.9852\n",
      "Epoch 121/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0473 - binary_accuracy: 0.9852\n",
      "Epoch 122/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0456 - binary_accuracy: 0.9852\n",
      "Epoch 123/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0454 - binary_accuracy: 0.9901\n",
      "Epoch 124/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0446 - binary_accuracy: 0.9852\n",
      "Epoch 125/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0445 - binary_accuracy: 0.9901\n",
      "Epoch 126/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0438 - binary_accuracy: 0.9852\n",
      "Epoch 127/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0442 - binary_accuracy: 0.9852\n",
      "Epoch 128/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0441 - binary_accuracy: 0.9852\n",
      "Epoch 129/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0432 - binary_accuracy: 0.9852\n",
      "Epoch 130/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0452 - binary_accuracy: 0.9802\n",
      "Epoch 131/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0420 - binary_accuracy: 0.9802\n",
      "Epoch 132/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0415 - binary_accuracy: 0.9852\n",
      "Epoch 133/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0416 - binary_accuracy: 0.9852\n",
      "Epoch 134/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0413 - binary_accuracy: 0.9901\n",
      "Epoch 135/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0406 - binary_accuracy: 0.9852\n",
      "Epoch 136/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0423 - binary_accuracy: 0.9802\n",
      "Epoch 137/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0414 - binary_accuracy: 0.9852\n",
      "Epoch 138/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0408 - binary_accuracy: 0.9852\n",
      "Epoch 139/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0405 - binary_accuracy: 0.9852\n",
      "Epoch 140/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0379 - binary_accuracy: 0.9852\n",
      "Epoch 141/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0416 - binary_accuracy: 0.9852\n",
      "Epoch 142/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0403 - binary_accuracy: 0.9852\n",
      "Epoch 143/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0405 - binary_accuracy: 0.9802\n",
      "Epoch 144/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0394 - binary_accuracy: 0.9802\n",
      "Epoch 145/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0391 - binary_accuracy: 0.9802\n",
      "Epoch 146/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0377 - binary_accuracy: 0.9852\n",
      "Epoch 147/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0385 - binary_accuracy: 0.9802\n",
      "Epoch 148/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0382 - binary_accuracy: 0.9852\n",
      "Epoch 149/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0422 - binary_accuracy: 0.9852\n",
      "Epoch 150/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0377 - binary_accuracy: 0.9852\n",
      "Epoch 151/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0384 - binary_accuracy: 0.9802\n",
      "Epoch 152/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0380 - binary_accuracy: 0.9852\n",
      "Epoch 153/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0370 - binary_accuracy: 0.9852\n",
      "Epoch 154/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0376 - binary_accuracy: 0.9852\n",
      "Epoch 155/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0372 - binary_accuracy: 0.9852\n",
      "Epoch 156/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0372 - binary_accuracy: 0.9852\n",
      "Epoch 157/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0374 - binary_accuracy: 0.9852\n",
      "Epoch 158/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0373 - binary_accuracy: 0.9852\n",
      "Epoch 159/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0359 - binary_accuracy: 0.9852\n",
      "Epoch 160/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0365 - binary_accuracy: 0.9852\n",
      "Epoch 161/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0359 - binary_accuracy: 0.9852\n",
      "Epoch 162/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0361 - binary_accuracy: 0.9852\n",
      "Epoch 163/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0356 - binary_accuracy: 0.9852\n",
      "Epoch 164/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0353 - binary_accuracy: 0.9852\n",
      "Epoch 165/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0347 - binary_accuracy: 0.9852\n",
      "Epoch 166/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0355 - binary_accuracy: 0.9852\n",
      "Epoch 167/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0349 - binary_accuracy: 0.9901\n",
      "Epoch 168/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0350 - binary_accuracy: 0.9852\n",
      "Epoch 169/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0346 - binary_accuracy: 0.9901\n",
      "Epoch 170/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0354 - binary_accuracy: 0.9852\n",
      "Epoch 171/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0346 - binary_accuracy: 0.9852\n",
      "Epoch 172/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0371 - binary_accuracy: 0.9802\n",
      "Epoch 173/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0339 - binary_accuracy: 0.9852\n",
      "Epoch 174/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0335 - binary_accuracy: 0.9852\n",
      "Epoch 175/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0342 - binary_accuracy: 0.9901\n",
      "Epoch 176/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0345 - binary_accuracy: 0.9852\n",
      "Epoch 177/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0348 - binary_accuracy: 0.9852\n",
      "Epoch 178/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0340 - binary_accuracy: 0.9852\n",
      "Epoch 179/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0326 - binary_accuracy: 0.9852\n",
      "Epoch 180/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0350 - binary_accuracy: 0.9852\n",
      "Epoch 181/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0360 - binary_accuracy: 0.9852\n",
      "Epoch 182/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0337 - binary_accuracy: 0.9901\n",
      "Epoch 183/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0341 - binary_accuracy: 0.9802\n",
      "Epoch 184/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0343 - binary_accuracy: 0.9901\n",
      "Epoch 185/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0349 - binary_accuracy: 0.9852\n",
      "Epoch 186/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0320 - binary_accuracy: 0.9901\n",
      "Epoch 187/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0327 - binary_accuracy: 0.9852\n",
      "Epoch 188/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0351 - binary_accuracy: 0.9852\n",
      "Epoch 189/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0332 - binary_accuracy: 0.9901\n",
      "Epoch 190/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0323 - binary_accuracy: 0.9901\n",
      "Epoch 191/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0327 - binary_accuracy: 0.9901\n",
      "Epoch 192/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9852\n",
      "Epoch 193/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0343 - binary_accuracy: 0.9852\n",
      "Epoch 194/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0313 - binary_accuracy: 0.9901\n",
      "Epoch 195/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0316 - binary_accuracy: 0.9901\n",
      "Epoch 196/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0340 - binary_accuracy: 0.9901\n",
      "Epoch 197/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0323 - binary_accuracy: 0.9901\n",
      "Epoch 198/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0319 - binary_accuracy: 0.9852\n",
      "Epoch 199/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9852\n",
      "Epoch 200/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0311 - binary_accuracy: 0.9901\n",
      "Epoch 201/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0321 - binary_accuracy: 0.9901\n",
      "Epoch 202/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0313 - binary_accuracy: 0.9852\n",
      "Epoch 203/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0314 - binary_accuracy: 0.9852\n",
      "Epoch 204/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0312 - binary_accuracy: 0.9852\n",
      "Epoch 205/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9802\n",
      "Epoch 206/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0309 - binary_accuracy: 0.9901\n",
      "Epoch 207/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0310 - binary_accuracy: 0.9852\n",
      "Epoch 208/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0322 - binary_accuracy: 0.9852\n",
      "Epoch 209/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0309 - binary_accuracy: 0.9901\n",
      "Epoch 210/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0315 - binary_accuracy: 0.9852\n",
      "Epoch 211/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0312 - binary_accuracy: 0.9852\n",
      "Epoch 212/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0312 - binary_accuracy: 0.9901\n",
      "Epoch 213/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0304 - binary_accuracy: 0.9901\n",
      "Epoch 214/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0323 - binary_accuracy: 0.9901\n",
      "Epoch 215/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0308 - binary_accuracy: 0.9901\n",
      "Epoch 216/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0303 - binary_accuracy: 0.9852\n",
      "Epoch 217/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0298 - binary_accuracy: 0.9901\n",
      "Epoch 218/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0303 - binary_accuracy: 0.9901\n",
      "Epoch 219/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0309 - binary_accuracy: 0.9901\n",
      "Epoch 220/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0325 - binary_accuracy: 0.9852\n",
      "Epoch 221/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0298 - binary_accuracy: 0.9901\n",
      "Epoch 222/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0302 - binary_accuracy: 0.9901\n",
      "Epoch 223/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0310 - binary_accuracy: 0.9901\n",
      "Epoch 224/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0300 - binary_accuracy: 0.9901\n",
      "Epoch 225/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0311 - binary_accuracy: 0.9901\n",
      "Epoch 226/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0329 - binary_accuracy: 0.9901\n",
      "Epoch 227/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0316 - binary_accuracy: 0.9901\n",
      "Epoch 228/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0328 - binary_accuracy: 0.9852\n",
      "Epoch 229/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0307 - binary_accuracy: 0.9852\n",
      "Epoch 230/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0289 - binary_accuracy: 0.9901\n",
      "Epoch 231/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0297 - binary_accuracy: 0.9901\n",
      "Epoch 232/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0299 - binary_accuracy: 0.9852\n",
      "Epoch 233/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0300 - binary_accuracy: 0.9852\n",
      "Epoch 234/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0293 - binary_accuracy: 0.9901\n",
      "Epoch 235/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0299 - binary_accuracy: 0.9901\n",
      "Epoch 236/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0292 - binary_accuracy: 0.9901\n",
      "Epoch 237/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0299 - binary_accuracy: 0.9901\n",
      "Epoch 238/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0294 - binary_accuracy: 0.9901\n",
      "Epoch 239/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0286 - binary_accuracy: 0.9901\n",
      "Epoch 240/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0310 - binary_accuracy: 0.9901\n",
      "Epoch 241/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0296 - binary_accuracy: 0.9901\n",
      "Epoch 242/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0301 - binary_accuracy: 0.9852\n",
      "Epoch 243/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0285 - binary_accuracy: 0.9901\n",
      "Epoch 244/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0285 - binary_accuracy: 0.9901\n",
      "Epoch 245/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0289 - binary_accuracy: 0.9901\n",
      "Epoch 246/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0282 - binary_accuracy: 0.9901\n",
      "Epoch 247/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0285 - binary_accuracy: 0.9901\n",
      "Epoch 248/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0281 - binary_accuracy: 0.9901\n",
      "Epoch 249/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0292 - binary_accuracy: 0.9852\n",
      "Epoch 250/250\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0292 - binary_accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a32d24f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss = 'mean_squared_error'\n",
    "loss = fuzz.loss_function\n",
    "optimizer = 'adam'\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "model = fuzz.model\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics)\n",
    "\n",
    "model.fit(np.array(X_train),\n",
    "          np.array(y_train),\n",
    "          epochs=250,\n",
    "          verbose=1,\n",
    "          batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.1073303,  5.8863463,  3.8469965],\n",
       "        [ 2.4748902,  4.0579185,  1.1891739],\n",
       "        [ 6.9911284,  1.0462298,  3.7106006],\n",
       "        [ 3.7091155, -0.3453039,  2.5200057]], dtype=float32),\n",
       " array([[3.9457917, 5.1618943, 2.0746884],\n",
       "        [3.2234733, 3.435901 , 2.1246395],\n",
       "        [2.0414689, 3.5269158, 2.0570922],\n",
       "        [1.4811075, 2.9864326, 1.6324853]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz._get_layer_weights('FuzzyRules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.6, 1.4, 0.2],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [4.8, 3.1, 1.6, 0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True, False, False],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = y_test == y_pred.round()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.sum() / acc.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 9ms/step\n",
      "Model Loss: 0.43104896\n",
      "Binary Accuracy: 95.6%\n"
     ]
    }
   ],
   "source": [
    "pred_loss, pred_bin_acc = model.evaluate(X_test, y_test)\n",
    "print('Model Loss: {:0.8f}'.format(pred_loss))\n",
    "print('Binary Accuracy: {:2.1f}%'.format(100*pred_bin_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'binary_accuracy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = fuzz._get_layer_weights('FuzzyRules')\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.title('Iris')\n",
    "plt.ylabel('x[0]')\n",
    "plt.xlabel('x[1]')\n",
    "plt.scatter([a[0] for a in X_train], [a[1] for a in X_train], c=(0,0,0), alpha=0.5,s=1)\n",
    "for i in range(0,fuzz.neurons):\n",
    "    ellipse = Ellipse((w[0][0][i], w[0][1][i]), w[1][0][i],w[1][1][i], color='r', fill=False)\n",
    "    ax = plt.gca()\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "plt.scatter(w[0][0], w[0][1], c=(1,0,0), alpha=0.8,s=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
